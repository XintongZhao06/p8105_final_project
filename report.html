<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Short-Form Video Analytics: Completion Rate and Trend Prediction</title>

<script src="site_libs/header-attrs-2.29/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.5.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="data.html">Data</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Topic 1
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="topic1.html">EDA</a>
    </li>
    <li>
      <a href="regression_analysis.html">Regression Analysis</a>
    </li>
  </ul>
</li>
<li>
  <a href="topic2.html">Topic 2</a>
</li>
<li>
  <a href="report.html">Report</a>
</li>
<li>
  <a href="https://github.com/XintongZhao06">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Short-Form Video Analytics: Completion Rate
and Trend Prediction</h1>

</div>


<div id="abstract" class="section level1">
<h1><strong>0 Abstract</strong></h1>
<p>A concise summary of project motivation, data, methods, and key
findings.</p>
</div>
<div id="motivation" class="section level1">
<h1><strong>1 Motivation</strong></h1>
<p>Short-form platforms such as TikTok and YouTube Shorts generate
massive volumes of user interaction data. Understanding patterns that
drive <strong>completion rate</strong> (viewer retention) and
<strong>trend label</strong> (whether a video becomes trending) provides
insight into how videos perform and how creators or platforms might
optimize content.</p>
<p>Our project is motivated by two central questions:</p>
<ul>
<li><strong>Which video attributes show statistical associations with
completion rate?</strong><br />
</li>
<li><strong>Can trend labels be predicted from metadata using machine
learning?</strong></li>
</ul>
<p>We aim to distill interpretable insights, not merely build
high-accuracy models. Completion rate is influenced by content quality
and recommendation algorithms, neither of which is directly measured.
Therefore, we expect relatively low explanatory power from traditional
statistical models, and the analysis is intended as a descriptive
exploration.</p>
</div>
<div id="related-work" class="section level1">
<h1><strong>2 Related Work</strong></h1>
<p>(Anything that inspired you, such as a paper, a web site, or
something we discussed in class.)</p>
<p>(We anticipate that your project will change somewhat over time;
these changes and the reasons for them should be documented!)</p>
</div>
<div id="initial-questions-and-project-evolution"
class="section level1">
<h1><strong>3 Initial Questions and Project Evolution</strong></h1>
<p>The project began with an interest in understanding viewer retention
by examining completion rate. Our initial plan included exploratory data
analysis, followed by regression modeling and then building a model
using machine learning methods to evaluate how to predict completion
rates from metadata. Early results showed that completion rate was
extremely difficult to predict, even when more flexible machine learning
models were applied. This outcome suggested that completion behavior is
strongly driven by unobserved factors such as creative quality and
recommendation exposure, which are not present in metadata. As a result,
completion rate was treated only as a descriptive target, and the focus
shifted to exploratory identification of structural associations rather
than building predictive models.</p>
<p>These findings also prompted us to adjust the scope of our research.
Since metadata did not seem to explain view completion rates well, we
began to consider whether other performance metrics were more suitable
for prediction. Trend labels emerged as a suitable alternative because
they may capture platform-level dynamics and rely less on unobserved
content attributes. This consideration led to the second part of the
project, which examines the extent to which trend labels can be
predicted using machine learning methods. The evolution of these
research questions reflects a growing understanding of both the
strengths and limits of metadata in explaining short-form video
performance.</p>
</div>
<div id="data" class="section level1">
<h1><strong>4 Data</strong></h1>
<div id="source-information" class="section level2">
<h2><strong>4.1 Source Information</strong></h2>
<ul>
<li><p><strong>Platform</strong>: <a
href="https://www.kaggle.com/datasets/tarekmasryo/youtube-shorts-and-tiktok-trends-2025">Kaggle</a></p></li>
<li><p><strong>Dataset Type</strong>: Social media analytics,
synthetic/curated dataset</p></li>
<li><p><strong>Size</strong>: ~50,000 video records</p></li>
<li><p><strong>Time Period</strong>: 2025 (January-September)</p></li>
</ul>
</div>
<div id="key-variables" class="section level2">
<h2><strong>4.1 Key Variables</strong></h2>
<div id="engagement-metrics" class="section level3">
<h3><strong>4.2.1 Engagement Metrics</strong></h3>
<ul>
<li><p><strong>views</strong>: Total views count</p></li>
<li><p><strong>likes</strong>: Likes count</p></li>
<li><p><strong>comments</strong>: Comments count</p></li>
<li><p><strong>shares</strong>: Shares count</p></li>
<li><p><strong>saves</strong>: Saves count</p></li>
<li><p><strong>completion_rate</strong>:
<code>avg_watch_time_sec / duration_sec</code></p></li>
<li><p><strong>engagement_rate</strong>:
<code>(likes+comments+shares+saves) / views</code></p></li>
</ul>
</div>
<div id="classification-target-variables" class="section level3">
<h3><strong>4.2.2 Classification &amp; Target Variables</strong></h3>
<ul>
<li><p><strong>completion_rate</strong></p></li>
<li><p><strong>trend_label</strong></p></li>
</ul>
</div>
</div>
<div id="data-characteristics" class="section level2">
<h2><strong>4.3 Data Characteristics</strong></h2>
<div id="data-transformations" class="section level3">
<h3><strong>4.3.1 Data Transformations</strong></h3>
<ul>
<li><p>Categorical variables converted to factors</p></li>
<li><p>Derived metrics</p></li>
</ul>
</div>
<div id="data-cleaning" class="section level3">
<h3><strong>4.3.2 Data Cleaning</strong></h3>
<p>There are <strong>no missing values</strong> in the dataset, so the
data cleaning process is not included.</p>
</div>
</div>
</div>
<div id="exploratory-data-analysis-eda" class="section level1">
<h1><strong>5 Exploratory Data Analysis (EDA)</strong></h1>
<div id="eda-completion-rate" class="section level2">
<h2><strong>5.1 EDA — Completion Rate</strong></h2>
<p>(Visualizations, summaries, and exploratory statistical analyses.
Justify the steps you took, and show any major changes to your
ideas.)</p>
</div>
<div id="eda-trend-label" class="section level2">
<h2><strong>5.2 EDA — Trend Label</strong></h2>
</div>
</div>
<div id="detailed-regression-ml-analysis" class="section level1">
<h1><strong>6 Detailed Regression &amp; ML Analysis</strong></h1>
<div id="topic-1-completion-rate-analysis" class="section level2">
<h2><strong>6.1 Topic 1: Completion Rate Analysis</strong></h2>
<div id="purpose-of-the-regression-analysis" class="section level3">
<h3><strong>6.1.1 Purpose of the Regression Analysis</strong></h3>
<p>Completion rate serves as a key performance metric for short-form
videos, reflecting how fully viewers watch a given video. Although
creators often attribute retention to content quality, narrative
structure, or emotional engagement, these elements are unobserved in
platform metadata. Our modeling objective is therefore not prediction,
but descriptive quantification of associations between completion_rate
and observable characteristics such as duration, engagement metrics,
posting timing, and creator attributes.</p>
<p>Given the inherent limitations of metadata and the complexity of
viewer behavior — shaped by recommendation algorithms, scrolling
patterns, and individual preferences — we expect the explanatory power
of the regression models to be modest. Nonetheless, regression analysis
still offers a clear way to assess which metadata features are
associated with completion rate and to identify where nonlinear or
structural patterns may warrant more flexible models.</p>
</div>
<div id="linear-regression-models" class="section level3">
<h3><strong>6.1.2 Linear Regression Models</strong></h3>
<p>We first developed three linear models to examine these associations:
(1) a baseline regression including only timing-related features; (2) an
engagement-augmented model that incorporates log-transformed interaction
metrics; and (3) a full specification that adds creator-level attributes
and applies backward stepwise selection to identify a more parsimonious
set of predictors. This progression allowed us to evaluate how the
explanatory contribution of different variable groups changes as the
model becomes more comprehensive. We then extended the analysis to
nonlinear GAM models to assess whether more flexible functional forms
capture additional structure or improve explanatory performance beyond
what linear models can provide.</p>
<div id="baseline-linear-regression" class="section level4">
<h4><strong>6.1.2.1 Baseline Linear Regression</strong></h4>
<p>The baseline regression evaluates how timing-related features and
basic video attributes relate to completion_rate. The estimated model
is:</p>
<p><span class="math display">\[
\begin{aligned}
\text{completion_rate}_i
&amp;= \beta_0
+ \beta_1 \,\text{event_season}_i
+ \beta_2 \,\text{is_weekend}_i \\
&amp;\quad + \beta_3 \,\text{duration_sec}_i
+ \beta_4 \,\text{upload_hour}_i
+ \varepsilon_i .
\end{aligned}
\]</span></p>
<div style="text-align: center;">
<img src="regression_images/model1.png" width="100%">
<p>
Table 6.1    Summary of baseline linear regression
</p>
</div>
<p>Table 6.1 reports the estimated coefficients and summarizes how basic
timing and structural attributes relate to completion rate. The
intercept reflects the expected completion rate for the reference
category, and while not substantively meaningful on its own, it serves
as the baseline against which other coefficients are interpreted.
Consistent with expectations, video duration emerges as the strongest
predictor: the coefficient for <code>duration_sec</code> is negative
(<span class="math inline">\(\beta_3\)</span> = -0.0009) and highly
significant (p-value &lt; 0.05), indicating that longer videos tend to
yield lower completion rates, even within the short-form format. Among
the seasonal indicators, only the Regular season shows a small positive
association (p-value = 0.041 &lt; 0.05). The remaining
<code>event_season</code> categories, as well as <code>is_weekend</code>
and <code>upload_hour</code>, do not exhibit statistically significant
effects, suggesting that broad posting time patterns have limited
influence on completion rate in this dataset.</p>
<p>Overall, the baseline model highlights duration as the primary
structural correlate of viewer retention, while other timing-related
features contribute little explanatory power. This motivates the
incorporation of engagement and creator-level variables in subsequent
models.</p>
</div>
<div id="engagement-augmented-linear-regression" class="section level4">
<h4><strong>6.1.2.2 Engagement-Augmented Linear Regression</strong></h4>
<p>To explore whether audience interaction patterns co-vary with viewer
retention, the second model adds log-transformed engagement metrics —
likes, comments, shares, and saves — to the baseline specification.
These variables allow us to examine the relationship between video
engagement signals and completion rates. The augmented model is
presented as follows:</p>
<p><span style="font-size: 95%;"> <span class="math display">\[
\begin{aligned}
\text{completion_rate}_i
&amp;= \beta_0
+ \beta_1 \,*\text{event_season}_i
+ \beta_2 \,*\text{is_weekend}_i
+ \beta_3 \,*\text{duration_sec}_i \\
&amp;\quad + \beta_4 \,*\text{upload_hour}_i + \beta_5
*\log(\text{likes}_i + 1)
+ \beta_6 *\log(\text{comments}_i + 1) \\
&amp;\quad + \beta_7 *\log(\text{shares}_i + 1)
+ \beta_8 *\log(\text{saves}_i + 1)
+ \varepsilon_i .
\end{aligned}
\]</span> </span></p>
<div style="text-align: center;">
<img src="regression_images/model2.png" width="100%">
<p>
Table 6.2    Summary of engagement-augmented linear regression
</p>
</div>
<p>Table 6.2 presents the augmented model. Duration remains the
strongest negative predictor, consistent the baseline finding. Among
engagement metrics, <code>log_likes</code> and <code>log_saves</code>
show statistically significant positive associations with
<code>completion_rate</code> (p &lt; 0.05). This pattern indicates that
videos with stronger engagement signals also tend to have higher
completion rates, although the association is correlational rather than
causal. In contrast, <code>log_comments</code> and
<code>log_shares</code> are not significant, indicating that not all
engagement forms are linked to retention. The timing-related predictors
(<code>event_season</code>, <code>is_weekend</code>, and
<code>upload_hour</code>) continue to show limited explanatory value,
reinforcing that temporal posting patterns do not strongly shape viewer
retention.</p>
<p>Overall, expanding the model to incorporate interaction measures
offers a modest improvement but does not fundamentally change the
structure of associations identified earlier.</p>
</div>
<div id="full-linear-model-and-stepwise-selection"
class="section level4">
<h4><strong>6.1.2.3 Full Linear Model and Stepwise
Selection</strong></h4>
<p>To examine whether creator attributes or stylistic choices add
explanatory value beyond engagement patterns, the third model introduces
creator-level variables such as log_creator_avg, creator_tier, and
has_emoji. We define the full model as follows:</p>
<p><span style="font-size: 95%;"> <span class="math display">\[
\begin{aligned}
\text{completion_rate}_i
&amp;= \beta_0
+ \beta_1 \,*\text{event_season}_i
+ \beta_2 \,*\text{is_weekend}_i
+ \beta_3 \,*\text{duration_sec}_i
+ \beta_4 \,*\text{upload_hour}_i \\
&amp;\quad + \beta_5 *\log(\text{likes}_i + 1)
+ \beta_6 *\log(\text{comments}_i + 1)
+ \beta_7 *\log(\text{shares}_i + 1)
+ \beta_8 *\log(\text{saves}_i + 1) \\
&amp;\quad + \beta_9 *\log(\text{creator_avg_views}_i + 1)
+ \beta_{10} *\text{creator_tier}_i
+ \beta_{11} *\text{has_emoji}_i
+ \varepsilon_i .
\end{aligned}
\]</span> </span></p>
<p>Because the full specification contains numerous correlated
predictors, a backward stepwise procedure is applied to identify a more
concise subset of variables. The results of final model are presented in
Table 6.3.</p>
<div style="text-align: center;">
<img src="regression_images/model3.png" width="100%">
<p>
Table 6.3    Summary of stepwise (backward) regression
</p>
</div>
<p><span style="font-size: 95%;"> <span class="math display">\[
\begin{aligned}
\widehat{\text{completion_rate}}_i
&amp;= \ 0.6638
- 0.0007932 \,*\text{duration_sec}_i
+ 0.008618 *\log(\text{likes}_i + 1) \\
&amp;\quad + 0.002520 *\log(\text{saves}_i + 1)
- 0.008323 *\log(\text{creator_avg_views}_i + 1) \\
&amp;\quad + 0.02303\, *\text{has_emoji}_i .
\end{aligned}
\]</span> </span></p>
<p>The backward stepwise model finally retains only five predictors —
<code>duration_sec</code>, <code>log_likes</code>,
<code>log_saves</code>, <code>log_creator_avg</code>, and
<code>has_emoji</code> — indicating that these features are the ones
most strongly associated with variation in completion rate. The negative
coefficient for <code>log_creator_avg</code> is particularly notable.
Holding other factors constant, videos from creators with larger average
viewership tend to show slightly lower completion rates. This may
reflect heterogeneous audience behavior or differences in content style
across creator tiers. Meanwhile, <code>has_emoji</code> shows a small
but statistically significant positive effect, suggesting that visual
cues in titles may enhance viewer engagement. Variables removed during
stepwise selection, such as the seasonal and posting-time indicators,
contributed little once the more informative predictors were
included.</p>
<p>Overall, the stepwise model produces a concise set of variables
strongly linked to completion rate. This provides a clear summary of the
linear relationships, establishing a useful baseline for further
exploration.</p>
</div>
<div id="comparison-of-linear-models" class="section level4">
<h4><strong>6.1.2.4 Comparison of Linear Models</strong></h4>
<p>The three linear models show small but incremental improvements in
fit as additional predictors are added. As shown in Table 6.4, the
baseline model explains only a small share of variation in
<code>completion_rate</code> (r-squared = 0.0183). Adding engagement
variables increases the r-squared to 0.0308, and the stepwise model
achieves the highest value at 0.0411.</p>
<div style="text-align: center;">
<img src="regression_images/linear_regression_comparison.png" width="60%">
<p>
Table 6.4    Comparison of linear regression models
</p>
</div>
<p>Despite these incremental differences, all three models ultimately
exhibit low r-squared. This is unsurprising in the context of short-form
video performance, where much of viewer retention is shaped by factors
not captured in metadata - such as creative quality, editing style,
narrative pacing, emotional tone, and topic relevance. Completion
outcomes are also influenced by platform recommendation systems, which
shape exposure patterns in ways not observable in the dataset. Moreover,
linear models impose additive and monotonic relationships that may be
too restrictive for inherently nonlinear viewing behaviors. Together,
these unobserved elements limit the explanatory power of linear models
and help clarify why metadata-based regressions account for only a small
fraction of the variation in completion rate.</p>
</div>
<div id="regression-diagnostics" class="section level4">
<h4><strong>6.1.2.5 Regression Diagnostics</strong></h4>
<p>To assess whether the stepwise model satisfies key regression
assumptions, we examine the standard set of diagnostic plots. These
plots provide insight into linearity, homoscedasticity, normality of
residuals, and the influence of individual observations.</p>
<div style="text-align: center;">
<p>
Figure 6.1    Diagnostic plots for the stepwise linear model
</p>
<p><img src="regression_images/diagnostic_checks.png" width="100%"></p>
</div>
<p>The Residuals vs Fitted and Scale–Location plots show slight changes
in residual spread across fitted values, indicating mild
heteroscedasticity and some non-linearity. The Q–Q plot reveals
noticeable deviations in the tails from a normal distribution; however,
this is also expected because Q–Q plots become highly sensitive with
large sample sizes and can highlight even very small departures from
normality. The Residuals vs Leverage plot shows a few moderately
high-leverage points, but none appear strongly influential.</p>
<p>Overall, the linear model remains adequate for exploratory purposes,
but the diagnostics indicate that its assumptions are not fully
satisfied and the linear specification may not fully capture the
underlying patterns in the data. These limitations motivate the use of
nonlinear approaches, such as smooth and wiggly GAM, to capture
potential nonlinear patterns that the linear specification may not fully
capture.</p>
</div>
</div>
<div id="nonlinear-modeling-and-model-comparison"
class="section level3">
<h3><strong>6.1.3 Nonlinear Modeling and Model Comparison</strong></h3>
<p>Building on the predictors retained from the stepwise linear model,
we extend the analysis to nonlinear specifications to assess whether
more flexible functional forms can better capture patterns in
completion_rate. In particular, we compare a standard linear model with
two generalized additive models (GAMs) that allow nonlinear effects of
the predictors.</p>
<div id="traintest-split-for-nonlinear-models" class="section level4">
<h4><strong>6.1.3.1 Train–Test Split for Nonlinear Models</strong></h4>
<p>To evaluate predictive performance while avoiding overfitting, we
randomly sampled 5,000 observations from the full dataset and applied
the same preprocessing steps used in earlier models. The resulting
dataset was then partitioned into an 80% training set and a 20% test
set. All nonlinear models were fit on the training data and evaluated on
the held-out test data.</p>
</div>
<div id="model-specifications-linear-vs-smooth-vs-wiggly-gam"
class="section level4">
<h4><strong>6.1.3.2 Model Specifications: Linear vs Smooth vs Wiggly
GAM</strong></h4>
<p>We estimate three models using the same predictor set identified
through stepwise selection:</p>
<ol style="list-style-type: decimal">
<li><p>Linear Model — assumes additive, linear effects for all
predictors.</p></li>
<li><p>Smooth GAM — allows predictors such as duration_sec to vary
smoothly, capturing gentle nonlinear trends.</p></li>
<li><p>Wiggly GAM — uses a higher degree of smoothness flexibility,
allowing complex and rapidly changing nonlinear shapes.</p></li>
</ol>
<p>These models represent a progression from simple to increasingly
flexible structures, enabling assessment of whether added nonlinearity
improves fit or merely introduces noise.</p>
</div>
<div id="visual-comparison-of-three-models" class="section level4">
<h4><strong>6.1.3.3 Visual Comparison of three models</strong></h4>
<p>To illustrate differences in model behavior, we visualize fitted
values against <code>duration_sec</code>, because it is a continuous
predictor that allows the linear, smooth, and wiggly models to produce
interpretable fitted curves. Variables such as <code>log_likes</code> or
<code>has_emoji</code> are either discrete or less suitable for
illustrating non-linear patterns.</p>
<div style="text-align: center;">
<p>
Figure 6.2    Visual comparison of linear, smooth GAM, and wiggly GAM
fits
</p>
<img src="regression_images/nonlinear_comparison.png" width="100%">
</div>
<p>Across all three models, the downward association between video
duration and completion_rate is clearly visible. The Linear Model
produces a simple declining line, while the Smooth GAM allows gradual
curvature but remains stable and consistent with overall trends. In
contrast, the Wiggly GAM shows highly fluctuating and unstable fits,
suggesting overfitting to noise rather than capturing meaningful
structure.</p>
</div>
<div id="cross-validation-performance-and-visualization"
class="section level4">
<h4><strong>6.1.3.4 Cross-Validation Performance and
Visualization</strong></h4>
<p>Although prediction is not the primary goal of our analysis,
cross-validated RMSE provides a useful way to compare how differently
structured models behave out of sample and whether added flexibility
leads to more stable estimates. Rather than interpreting RMSE as a
measure of forecasting accuracy, we use it here to assess the extent to
which each model captures consistent patterns versus overfitting
noise.</p>
<div style="text-align: center;">
<p>
Figure 6.3    RMSE distributions for the linear and GAM models
</p>
<p><img src="regression_images/RMSE_distribution.png" width="100%"></p>
</div>
<p>The RMSE distributions show that the Linear Model and Smooth GAM
produce similarly low and stable error levels across folds, indicating
that their fitted relationships generalize reasonably well to held-out
data. In contrast, the Wiggly GAM exhibits both higher RMSE values and
substantially greater variability, showing the instability observed in
its fitted curve. This pattern reinforces the conclusion that excessive
model flexibility primarily captures sampling noise rather than
meaningful structure in the relationship between duration and completion
rate.</p>
<p>Overall, these results suggest that modest nonlinear flexibility can
be informative, but highly wiggly specifications offer little additional
insight and reduce model stability. This indicates that simpler models
are better suited for summarizing the underlying relationships in the
data and align well with the exploratory goals of Topic 1.</p>
</div>
</div>
<div id="conclusion-of-regression-findings" class="section level3">
<h3><strong>6.1.4 Conclusion of Regression Findings</strong></h3>
<p>The regression analyses collectively provide a structured overview of
how metadata features relate to short-form video completion rates.
Across all model specifications, video duration consistently emerges as
the strongest and most stable correlate of completion rate, exhibiting a
negative association in all models. Engagement-related variables such as
<code>log_likes</code> and <code>log_saves</code> also contribute
meaningfully once introduced, suggesting that videos that prompt
stronger viewer interaction tend to retain audiences slightly better.
Creator-level factors, particularly <code>log_creator_avg</code>, show
weaker and inverse relationships, indicating that larger creators do not
necessarily achieve higher completion rates.</p>
<p>Although adding predictors improves model fit incrementally, the
overall explanatory power remains low, with the best linear model
achieving an r-squared of approximately 0.041. This reflects the
inherent limitation of metadata, as viewer retention is a complex
outcome shaped by uncaptured features such as creative quality,
narrative structure, editing choices, emotional resonance, and platform
dynamics.</p>
<p>Nonlinear modeling further highlights these constraints. The Smooth
GAM captures mild curvature but offers only marginal improvements over
the linear specification, while the Wiggly GAM overfits and performs
poorly out of sample. Therefore, these results show that more flexible
functional forms do not substantially enhance predictive accuracy,
reinforcing the conclusion that metadata explains only a small portion
of completion behavior.</p>
<p>Overall, the regression analysis provides useful descriptive insight
into how structural and engagement-related attributes relate to
completion rate, but it also underscores the central role of unobserved
creative and algorithmic factors. These findings motivate the
exploration of richer feature sets or alternative modeling approaches in
future work, while also providing a clear baseline for interpreting
patterns in video performance.</p>
</div>
</div>
<div id="topic-2-trend-prediction" class="section level2">
<h2><strong>6.2 Topic 2: Trend Prediction</strong></h2>
<div id="purpose-of-the-ml-analysis" class="section level3">
<h3><strong>6.2.1 Purpose of the ML Analysis</strong></h3>
<p>We applyed several algorthms designed to predict popularity trends
for short-form videos. By analyzing extensive video data, we identify
patterns in viral content and assess the breakout potential of new
videos. By testing multiple algorithms, we identify the most accurate
predictive model, providing data-driven support for content platforms,
creators, and advertisers.</p>
</div>
<div id="data-preparation-and-exploration" class="section level3">
<h3><strong>6.2.2 Data Preparation and Exploration</strong></h3>
<div id="dataset-characteristics" class="section level4">
<h4><strong>6.2.2.1 Dataset Characteristics</strong></h4>
<p>We created a simulated dataset of 50,000 samples with the following
characteristics:</p>
<ul>
<li><p><strong>Platform Distribution</strong>: 60% TikTok, 40%
YouTube</p></li>
<li><p><strong>Content Categories</strong>: Entertainment, Music,
Sports, Education, Gaming</p></li>
<li><p><strong>Creator Tiers</strong>: Micro (50%), Mid (30%), Macro
(15%), Star (5%)</p></li>
<li><p><strong>Key Metrics</strong>: Title length, text richness,
comment rate, share rate, daily views</p></li>
</ul>
</div>
</div>
<div id="target-variable-construction" class="section level3">
<h3><strong>6.2.2.2 Target Variable Construction</strong></h3>
<p>We constructed an <strong>Engagement Score</strong> using the
following weighted formula:</p>
<p><span class="math display">\[
\begin{aligned}
\text{Engagement Score} = &amp;
\left(\frac{\text{comment_rate}}{0.02}\right) \times 0.2 \\
                         &amp; +
\left(\frac{\text{share_rate}}{0.005}\right) \times 0.3 \\
                         &amp; +
\left(\frac{\text{views_per_day}}{50000}\right) \times 0.2 \\
                         &amp; + \text{text_richness} \times 0.1 \\
                         &amp; + \text{weekend_hashtag_boost} \times 0.1
\\
                         &amp; + \text{creator_tier_bonus} \\
                         &amp; + N(0, 0.2)
\end{aligned}
\]</span></p>
<p>Where the creator tier bonus is defined as:</p>
<p><span class="math display">\[
\text{creator_tier_bonus} =
\begin{cases}
0.5 &amp; \text{if Star} \\
0.3 &amp; \text{if Macro} \\
0.1 &amp; \text{if Mid} \\
0 &amp; \text{if Micro}
\end{cases}
\]</span></p>
<p>Based on the Engagement Score, videos are classified into three trend
categories:</p>
<ul>
<li><p><strong>Low Trend (0)</strong>: Engagement Score ≤ 0.8</p></li>
<li><p><strong>Medium Trend (1)</strong>: 0.8 &lt; Engagement Score ≤
1.5</p></li>
<li><p><strong>High Trend (2)</strong>: Engagement Score &gt;
1.5</p></li>
</ul>
</div>
<div id="feature-engineering" class="section level3">
<h3><strong>6.2.3 Feature Engineering</strong></h3>
<p>We created three interaction features to capture complex
relationships:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Platform-Tier Interaction</strong>: Combines platform
type with creator tier</p>
<p><span class="math display">\[
\text{platform_tier} = \text{platform} \oplus \text{creator_tier}
\]</span></p></li>
<li><p><strong>Region-Category Interaction</strong>: Combines geographic
region with content category</p>
<p><span class="math display">\[
\text{region_category} = \text{region} \oplus \text{category}
\]</span></p></li>
<li><p><strong>Engagement Velocity</strong>: Composite metric measuring
virality speed</p>
<p><span class="math display">\[
\text{engagement_velocity} = \text{views_per_day} \times
(\text{comment_rate} + \text{share_rate})
\]</span></p></li>
</ol>
<p>Where <span class="math inline">\(\oplus\)</span> denotes feature
concatenation.</p>
<p>The final model utilizes 15 features including:</p>
<ul>
<li><p>12 original features (platform, region, category, traffic_source,
device_brand, creator_tier, title_len, text_richness, comment_rate,
share_rate, views_per_day, weekend_hashtag_boost)</p></li>
<li><p>3 interaction features (platform_tier, region_category,
engagement_velocity)</p></li>
</ul>
</div>
<div id="data-preprocessing" class="section level3">
<h3><strong>6.2.4 Data Preprocessing</strong></h3>
<div id="data-splitting" class="section level4">
<h4><strong>6.2.4.1 Data Splitting</strong></h4>
<p>The dataset was randomly split into training (80%) and testing (20%)
sets while maintaining proportional representation of each trend class
in both subsets.</p>
</div>
<div id="feature-transformation" class="section level4">
<h4><strong>6.2.4.1 Feature Transformation</strong></h4>
<ul>
<li><p><strong>Numerical Features</strong>: Standardized to zero mean
and unit variance</p></li>
<li><p><strong>Categorical Features</strong>: Transformed using one-hot
encoding</p></li>
</ul>
</div>
</div>
<div id="model-definition" class="section level3">
<h3><strong>6.2.5 Model Definition</strong></h3>
<p>We tested six machine learning models:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Random Forest</strong>: Ensemble of 200 decision trees
with maximum depth 15</p></li>
<li><p><strong>Gradient Boosting</strong>: 200 sequential trees with
learning rate <span class="math inline">\(\eta = 0.1\)</span></p></li>
<li><p><strong>Extra Trees</strong>: Extremely randomized trees variant
with 200 estimators</p></li>
<li><p><strong>Neural Network</strong>: Multi-layer perceptron with
architecture <span class="math inline">\([100, 50]\)</span>
neurons</p></li>
<li><p><strong>Support Vector Machine</strong>: RBF kernel with
regularization <span class="math inline">\(C = 1.0\)</span></p></li>
<li><p><strong>Logistic Regression</strong>: Linear classifier with
one-vs-rest strategy</p></li>
</ol>
</div>
<div id="model-training-and-evaluation" class="section level3">
<h3><strong>6.2.6 Model Training and Evaluation</strong></h3>
<div id="evaluation-metrics" class="section level4">
<h4><strong>6.2.6.1 Evaluation Metrics</strong></h4>
<p>Models were evaluated using multiple metrics:</p>
<ul>
<li><p><strong>Accuracy</strong></p></li>
<li><p><strong>Macro-average F1 Score</strong></p></li>
<li><p><strong>Weighted-average F1 Score</strong></p></li>
<li><p><strong>AUC-OVR</strong></p></li>
<li><p><strong>5-Fold Cross-Validation Accuracy</strong></p></li>
</ul>
</div>
<div id="training-process" class="section level4">
<h4><strong>6.2.6.2 Training Process</strong></h4>
<p>All models were trained using identical preprocessing pipelines to
ensure fair comparison, with performance evaluated on the held-out test
set.</p>
</div>
</div>
<div id="results-comparison" class="section level3">
<h3><strong>6.2.7 Results Comparison</strong></h3>
<div id="performance-ranking" class="section level4">
<h4><strong>6.2.7.1 Performance Ranking</strong></h4>
<p>Gradient Boosting demonstrated superior performance across all
metrics:</p>
<p><img src="classification_model_comparison.png" /></p>
</div>
</div>
<div id="best-model-analysis" class="section level3">
<h3><strong>6.2.8 Best Model Analysis</strong></h3>
<p>The Gradient Boosting model achieved the following confusion
matrix:</p>
<p><img src="classification_confusion_matrix.png" /></p>
<p>The model demonstrates strong performance distinguishing Low from
High trends but shows some confusion at the Medium-High boundary, with
206 High-trend videos misclassified as Medium.</p>
</div>
<div id="feature-importance-analysis" class="section level3">
<h3><strong>6.2.9 Feature Importance Analysis</strong></h3>
<p>The Gradient Boosting model revealed the following feature importance
ranking:</p>
<p><img src="classification_feature_importance.png" /></p>
<p>Analysis confirms user interaction metrics (particularly sharing and
commenting) are the primary predictors of video trends, accounting for
65% of the model’s decision-making.</p>
</div>
</div>
</div>
<div id="discussion" class="section level1">
<h1><strong>7. Discussion</strong></h1>
<p>(What were your findings? Are they what you expect? What insights
into the data can you make?)</p>
<div id="discussion-of-completion-rate" class="section level2">
<h2><strong>7.1 Discussion of Completion Rate </strong></h2>
<p>The regression results reveal several clear patterns in the
relationship between video features and view completion rates. Among all
models, video length consistently has the strongest influence. Longer
videos tend to have lower view completion rates, which aligns with
expectations for short-video platforms, as viewers prefer quick and
easy-to-understand content. Interaction metrics such as likes and saves
are also positively correlated with view completion rates, indicating
that videos that retain viewers tend to generate more interaction. More
Surprisingly, an unexpected finding is that creator-level attributes,
including average historical views, have a weak and even negative
correlation with view completion rates. This suggests that having a
large audience does not guarantee high retention rates, and content
features may be more important than creator scale.</p>
<p>Some results align with intuition, particularly the significant
impact of duration and interaction metrics. However, the limited impact
of creator attributes and posting time variables is unexpected. The
consistently low R-squared value across all models also indicate that
these predictors explain only a small portion of the variation in view
completion rates. Adding more predictors provides limited improvement,
further suggesting that metadata only captures some of the potential
factors influencing viewer retention, and many important factors are not
included in the dataset.</p>
<p>These findings offer several broader insights. View completion rates
appear to depend more on video-level quality, such as content design,
thematic appeal, than on the creator’s identity or posting time. The low
R-squared value confirms that most determinants of retention, including
creative quality and algorithmic exposure, are not reflected in the
existing variables. Furthermore, the non-linear model shows little
improvement over the linear model, suggesting that the primary
limitation lies in the lack of relevant content-level information rather
than the functional form of the model. In conclusion, metadata can
reveal some meaningful patterns, but it can only explain a small
fraction of audience behavior on short video platforms.</p>
</div>
<div id="discussion-of-trend-prediction" class="section level2">
<h2><strong>7.2 Discussion of Trend Prediction</strong></h2>
<p>The analysis reveals several significant findings that largely align
with expectations from short-form video platform dynamics. The superior
performance of Gradient Boosting was anticipated, given its proven
effectiveness in handling structured data with complex feature
interactions. What exceeded expectations was the magnitude of difference
between models, with Gradient Boosting achieving 3.2% higher accuracy
than its nearest competitor.</p>
<p>Our research results show that the proposed trend prediction system
effectively captures meaningful behavioral patterns in short video
participation. High, medium and low trend categories show clear and
consistent separations in key indicators such as views, likes, comments,
shares and saves. This model is highly consistent with people’s
expectations: the higher the trend of a video, the more user stickiness
it will naturally accumulate and accelerate its visibility in the
platform’s recommendation ecosystem. The distribution of user stickiness
scores further validates the reliability of the constructed tags - each
category forms a different group, which indicates that our feature
design has successfully captured the potential drivers of viral
spread.</p>
</div>
</div>
<div id="limitations-and-future-work" class="section level1">
<h1><strong>8 Limitations and Future Work</strong></h1>
<p>For <strong>Topic 1</strong>, a major limitation of regression
analysis is that it models all videos data as a single merged dataset
without distinguishing between different platforms, languages or content
categories. Because short videos vary greatly in purpose, audience, and
cultural context, merging all observations introduces significant
heterogeneity. This weakens true relationships, makes some predictors
insignificant, and masks confounding patterns that may exist in specific
subgroups. The large sample size further exacerbates this problem. In
addition, the consistently low R-squared values across all models
indicate that the current set of metadata variables captures only a
small portion of the factors influencing completion rate. This weak
model fit may reflect not only the limits of metadata but also the
absence of important content-level or behaviour-level variables that are
not observable in the dataset. Therefore, in future research, we should
not only expand the breadth of observed variables but also use
stratified or subgroup analysis to better control the model and obtain
more accurate regressions. For example, completion rate can be modeled
separately by language or platform to determine whether the observed
correlations are consistent across different content types or whether
they are masked by confounding effects in the aggregate dataset. This
can also help to identify confounding factors specific to each category
and more clearly explain differences in completion rates across
different video types.</p>
<p>For <strong>Topic 2</strong>，although the proposed system
demonstrates a strong predictive ability for short video trends, there
are still some limitations, providing opportunities for future
enhancement. Firstly, the dataset relies on synthetic or proxy-generated
behavioral patterns, which means that the participation relationships in
model learning may not fully capture platform-specific nuances or
rapidly evolving user habits in real-world environments. In addition,
the current functional design mainly focuses on structured metadata and
digital interaction metrics, but does not incorporate multimodal
elements such as video content, audio attributes, or text semantics,
which are known to have a significant impact on viral spread. The
contemporaneity of social trends has also been simplified. These models
handle each sample independently instead of modeling the dynamic trend
propagation over time. Finally, through advanced technologies such as
transformer-based architectures, self-supervised representation
learning, and automatic hyperparameter optimization, the model
performance can be further enhanced.</p>
<p>In future work, integrating real platform data streams, expanding the
feature space to include visual and NLP-based content signals, and
adopting time series prediction methods, such as sequence models or
graph-based diffusion learning, will enable the system to better track
emerging cultural patterns. Deploying the model into a real-time
feedback loop and evaluating it under production constraints will
further verify its practical value for content creators, marketers, and
recommendation systems.</p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
