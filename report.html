<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Short-Form Video Analytics: Completion Rate and Trend Prediction</title>

<script src="site_libs/header-attrs-2.29/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.5.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="data.html">Data</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Topic 1
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="topic1.html">EDA</a>
    </li>
    <li>
      <a href="regression_analysis.html">Regression Analysis</a>
    </li>
  </ul>
</li>
<li>
  <a href="topic2.html">Topic 2</a>
</li>
<li>
  <a href="report.html">Report</a>
</li>
<li>
  <a href="https://github.com/XintongZhao06">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Short-Form Video Analytics: Completion Rate
and Trend Prediction</h1>

</div>


<div id="abstract" class="section level1">
<h1><strong>0. Abstract</strong></h1>
<p>This project investigates two key aspects of short-form video
performance: <strong>completion rate</strong> (viewer retention) and
<strong>trend label prediction</strong> (video popularity level).</p>
<p>Using a curated dataset of nearly 50,000 TikTok and YouTube Shorts
videos, we:</p>
<ol style="list-style-type: decimal">
<li><strong>Conduct extensive exploratory analysis</strong> to
characterize distributions, temporal patterns, and content-level
differences</li>
<li><strong>Develop regression models</strong> examining metadata
features—duration, engagement metrics, creator tier, and stylistic
attributes—and their statistical associations with completion rate</li>
<li><strong>Build machine learning models</strong> to predict trend
labels constructed from weighted engagement scores</li>
</ol>
<div id="key-findings" class="section level2">
<h2>Key Findings</h2>
<p><strong>Completion Rate Analysis:</strong> Duration emerges as the
strongest correlate of retention, while overall explanatory power
remains low due to unobserved creative and algorithmic factors.</p>
<p><strong>Trend Prediction:</strong> Gradient Boosting yields the
highest performance across accuracy, F1, and cross-validation metrics,
successfully distinguishing low, medium, and high-trend content through
platform–tier dynamics, regional differences, and engagement
velocity.</p>
</div>
<div id="contributions" class="section level2">
<h2>Contributions</h2>
<p>This project offers a dual contribution: - <strong>Descriptive
insights</strong> into structural factors influencing viewer retention -
<strong>A practical framework</strong> for predicting video popularity
using platform metadata</p>
<p>Limitations related to metadata coverage, content heterogeneity, and
synthetic data generation are discussed, along with directions for
future multimodal and time-aware modeling.</p>
</div>
</div>
<div id="motivation" class="section level1">
<h1><strong>1. Motivation</strong></h1>
<p>Short-form platforms such as TikTok and YouTube Shorts generate
massive volumes of user interaction data. Understanding patterns that
drive <strong>completion rate</strong> (viewer retention) and
<strong>trend label</strong> (video popularity) provides insight into
content performance and optimization strategies.</p>
<p>As competition for user attention intensifies and platform algorithms
become increasingly opaque, identifying measurable, metadata-based
signals of performance becomes both practically valuable and
analytically challenging.</p>
<div id="research-questions" class="section level2">
<h2>Research Questions</h2>
<p>Our project is motivated by two central questions:</p>
<div
id="question-1-which-video-attributes-show-statistical-associations-with-completion-rate"
class="section level3">
<h3><strong>Question 1: Which video attributes show statistical
associations with completion rate?</strong></h3>
<p>Completion rate is one of the most direct indicators of viewer
interest, yet it is also shaped by unobserved content qualities such as:
- Pacing and narrative structure - Editing style and visual quality -
Emotional engagement - Algorithmic exposure patterns</p>
<p>By examining observable metadata—including duration, engagement
metrics, posting timing, and creator attributes—we aim to understand
which elements have consistent and interpretable associations with
retention.</p>
<blockquote>
<p><strong>Note:</strong> Rather than predicting retention with high
accuracy, our goal is to clarify how and why certain structural
attributes relate to viewer behavior.</p>
</blockquote>
</div>
<div
id="question-2-can-trend-labels-be-predicted-from-metadata-using-machine-learning"
class="section level3">
<h3><strong>Question 2: Can trend labels be predicted from metadata
using machine learning?</strong></h3>
<p>Emerging trends on short-form platforms are influenced by: - Social
contagion dynamics - Algorithmic amplification - Cross-platform cultural
patterns</p>
<p>Trend labels, constructed from multi-dimensional engagement metrics,
provide an alternative perspective on video performance that may be more
predictable than completion rate. This motivates our second line of
inquiry: whether machine-learning models can effectively classify videos
into <strong>Low, Medium, and High Trend</strong> categories using
platform- and creator-level metadata, interaction features, and designed
engagement metrics.</p>
</div>
</div>
<div id="methodological-approach" class="section level2">
<h2>Methodological Approach</h2>
<p>Beyond these two questions, the project is guided by a broader
methodological motivation: <strong>to understand the limits and
possibilities of metadata analytics</strong> in a domain dominated by
creative expression, algorithmic influence, and rapidly evolving user
behavior.</p>
<div id="why-completion-rate-is-challenging" class="section level3">
<h3>Why Completion Rate is Challenging</h3>
<p>Completion rate, by its nature, is tightly linked to content
quality—which is not directly observable—so we anticipate low
explanatory power from statistical models. This expectation shapes our
approach: instead of treating prediction as the primary objective, we
emphasize: - Descriptive modeling - Structural pattern identification -
Model interpretability</p>
</div>
<div id="why-trend-prediction-may-work-better" class="section level3">
<h3>Why Trend Prediction May Work Better</h3>
<p>The shift to trend prediction acknowledges that some aspects of video
popularity may be more amenable to machine learning. Engagement-driven
trend labels: - Capture richer behavioral signals than completion rate
alone - May reveal platform-level dynamics that metadata can
meaningfully approximate</p>
</div>
</div>
<div id="project-vision" class="section level2">
<h2>Project Vision</h2>
<p>Overall, the project is driven by a desire to <strong>bridge
interpretability and predictability</strong>, examining what metadata
can reveal about short-form video performance—and where its limitations
begin.</p>
</div>
</div>
<div id="related-work" class="section level1">
<h1><strong>2. Related Work</strong></h1>
<p>This project focuses on completion rate analysis and trend prediction
for short-form videos, drawing inspiration from practical research in
the short-form video field, industry reports, and class discussions.</p>
<div id="academic-research-foundations" class="section level2">
<h2>Academic Research Foundations</h2>
<div id="short-video-engagement-dynamics" class="section level3">
<h3>Short-Video Engagement Dynamics</h3>
<p>Key insights include studies on TikTok and YouTube Shorts
performance, which identify <strong>video duration</strong> and
<strong>upload timing</strong> as critical factors influencing
completion rates. These findings guided the focus on temporal patterns
and content characteristics in our Exploratory Data Analysis (EDA).</p>
</div>
<div id="engagement-rate-distributions" class="section level3">
<h3>Engagement Rate Distributions</h3>
<p>Research on short-video metrics notes that engagement rates exhibit
<strong>skewed distributions</strong>, consistent with our observation
of right-skewed engagement rates. This supports the use of
<strong>logarithmic transformations</strong> for modeling.</p>
</div>
</div>
<div id="industry-resources" class="section level2">
<h2>Industry Resources</h2>
<p>Industry resources played a vital role in shaping our approach:</p>
<ul>
<li><strong>Short-form video datasets</strong> from Kaggle provided
structural templates</li>
<li><strong>Platform-specific reports</strong> (e.g., TikTok Creator
Trend Reports) informed feature selection, such as:
<ul>
<li>Creator tiers</li>
<li>Hashtag performance metrics</li>
<li>Platform-specific engagement patterns</li>
</ul></li>
</ul>
</div>
<div id="methodological-guidance-from-coursework"
class="section level2">
<h2>Methodological Guidance from Coursework</h2>
<div id="handling-imbalanced-data" class="section level3">
<h3>Handling Imbalanced Data</h3>
<p>Class discussions on predictive modeling for imbalanced data led to
the adoption of: - <strong>Weighted F1-scores</strong> for evaluation -
<strong>Stratified cross-validation</strong> to address uneven
distribution of trend labels (Low/Medium/High)</p>
</div>
<div id="eda-best-practices" class="section level3">
<h3>EDA Best Practices</h3>
<p>Courses on EDA best practices guided the development of a systematic
analytical framework, prioritizing: 1. Analysis of key metrics 2.
Temporal pattern identification 3. Platform difference characterization
4. Model development informed by exploratory insights</p>
</div>
</div>
<div id="project-evolution" class="section level2">
<h2>Project Evolution</h2>
<div id="initial-focus-completion-rate-prediction"
class="section level3">
<h3>Initial Focus: Completion Rate Prediction</h3>
<p>The project initially planned to focus solely on completion rate
prediction using standard regression and machine learning
approaches.</p>
</div>
<div id="pivot-to-multi-metric-analysis" class="section level3">
<h3>Pivot to Multi-Metric Analysis</h3>
<p>This adjustment stemmed from insights from <strong>multi-metric
engagement scoring frameworks</strong>—combining comments, shares, and
views provides a more comprehensive reflection of content popularity
than completion rate alone.</p>
</div>
<div id="platform-specific-behavior" class="section level3">
<h3>Platform-Specific Behavior</h3>
<p>Research on platform-specific user behavior led to the addition of
<strong>interaction features</strong> (e.g., platform-creator tier
combinations) in feature engineering, as engagement drivers differ
between platforms like TikTok and YouTube Shorts.</p>
</div>
</div>
<div id="integration-of-external-experience" class="section level2">
<h2>Integration of External Experience</h2>
<p>These adjustments are based on the integration of external
experience, aiming to enhance the project’s: - <strong>Practical
applicability</strong> for content creators and platforms -
<strong>Predictive accuracy</strong> through informed feature
engineering - <strong>Analytical rigor</strong> through methodologically
sound approaches</p>
</div>
</div>
<div id="initial-questions-and-project-evolution"
class="section level1">
<h1><strong>3. Initial Questions and Project Evolution</strong></h1>
<div id="starting-point-focus-on-completion-rate"
class="section level2">
<h2>Starting Point: Focus on Completion Rate</h2>
<p>The project began with an interest in understanding viewer retention
by examining completion rate. Our initial plan included:</p>
<ol style="list-style-type: decimal">
<li><strong>Exploratory data analysis</strong> to identify patterns and
relationships</li>
<li><strong>Regression modeling</strong> to quantify associations
between metadata and retention</li>
<li><strong>Machine learning models</strong> to evaluate predictive
performance</li>
</ol>
</div>
<div id="the-reality-check-low-predictability" class="section level2">
<h2>The Reality Check: Low Predictability</h2>
<p>Early results revealed a critical finding: <strong>completion rate
was extremely difficult to predict</strong>, even when more flexible
machine learning models were applied.</p>
<div id="why-was-this-challenging" class="section level3">
<h3>Why Was This Challenging?</h3>
<p>This outcome suggested that completion behavior is strongly driven by
<strong>unobserved factors</strong> such as: - Creative quality and
production value - Narrative pacing and emotional resonance - Visual
aesthetics and editing techniques - Algorithmic recommendation exposure
- Individual viewer preferences and context</p>
<p>These elements are not present in metadata and fundamentally limit
predictive power.</p>
</div>
</div>
<div id="strategic-pivot-from-prediction-to-description"
class="section level2">
<h2>Strategic Pivot: From Prediction to Description</h2>
<p>As a result, completion rate was treated <strong>only as a
descriptive target</strong>, and the focus shifted to: -
<strong>Exploratory identification</strong> of structural associations -
<strong>Interpretable quantification</strong> of relationships between
observable features and retention - <strong>Understanding
limitations</strong> of metadata-based modeling</p>
<p>Rather than forcing predictive accuracy, we embraced a more modest
and scientifically appropriate goal: <strong>understanding what metadata
can and cannot tell us</strong> about viewer behavior.</p>
</div>
<div id="expanding-scope-the-search-for-predictable-targets"
class="section level2">
<h2>Expanding Scope: The Search for Predictable Targets</h2>
<p>These findings prompted us to adjust the scope of our research. Since
metadata did not explain view completion rates well, we began to
consider whether <strong>other performance metrics were more suitable
for prediction</strong>.</p>
<div id="why-trend-labels" class="section level3">
<h3>Why Trend Labels?</h3>
<p><strong>Trend labels</strong> emerged as a suitable alternative
because they:</p>
<ol style="list-style-type: decimal">
<li><strong>Capture platform-level dynamics</strong> rather than
individual viewing decisions</li>
<li><strong>Rely on multiple engagement signals</strong> (comments,
shares, saves, views) rather than a single metric</li>
<li><strong>May be less dependent</strong> on unobserved content
attributes</li>
<li><strong>Reflect cumulative social behavior</strong> that metadata
might better approximate</li>
</ol>
</div>
</div>
<div id="the-second-research-focus" class="section level2">
<h2>The Second Research Focus</h2>
<p>This consideration led to the second part of the project, which
examines <strong>the extent to which trend labels can be predicted using
machine learning methods</strong>.</p>
</div>
<div id="reflection-on-evolution" class="section level2">
<h2>Reflection on Evolution</h2>
<p>The evolution of these research questions reflects a growing
understanding of both: - <strong>The strengths of metadata
analytics</strong>: identifying structural patterns and platform
differences - <strong>The limits of metadata analytics</strong>:
capturing creative quality and individual viewer behavior</p>
<p>This adaptive approach demonstrates scientific maturity—recognizing
when initial hypotheses need revision and pivoting to more tractable and
meaningful research questions.</p>
</div>
</div>
<div id="data" class="section level1">
<h1><strong>4 Data</strong></h1>
<div id="source-information" class="section level2">
<h2><strong>4.1 Source Information</strong></h2>
<ul>
<li><p><strong>Platform</strong>: <a
href="https://www.kaggle.com/datasets/tarekmasryo/youtube-shorts-and-tiktok-trends-2025">Kaggle</a></p></li>
<li><p><strong>Dataset Type</strong>: Social media analytics,
synthetic/curated dataset</p></li>
<li><p><strong>Size</strong>: ~50,000 video records</p></li>
<li><p><strong>Time Period</strong>: 2025 (January-September)</p></li>
</ul>
</div>
<div id="key-variables" class="section level2">
<h2><strong>4.1 Key Variables</strong></h2>
<div id="engagement-metrics" class="section level3">
<h3><strong>4.2.1 Engagement Metrics</strong></h3>
<ul>
<li><p><strong>views</strong>: Total views count</p></li>
<li><p><strong>likes</strong>: Likes count</p></li>
<li><p><strong>comments</strong>: Comments count</p></li>
<li><p><strong>shares</strong>: Shares count</p></li>
<li><p><strong>saves</strong>: Saves count</p></li>
<li><p><strong>completion_rate</strong>:
<code>avg_watch_time_sec / duration_sec</code></p></li>
<li><p><strong>engagement_rate</strong>:
<code>(likes+comments+shares+saves) / views</code></p></li>
</ul>
</div>
<div id="classification-target-variables" class="section level3">
<h3><strong>4.2.2 Classification &amp; Target Variables</strong></h3>
<ul>
<li><p><strong>completion_rate</strong></p></li>
<li><p><strong>trend_label</strong></p></li>
</ul>
</div>
</div>
<div id="data-characteristics" class="section level2">
<h2><strong>4.3 Data Characteristics</strong></h2>
<div id="data-transformations" class="section level3">
<h3><strong>4.3.1 Data Transformations</strong></h3>
<ul>
<li><p>Categorical variables converted to factors</p></li>
<li><p>Derived metrics</p></li>
</ul>
</div>
<div id="data-cleaning" class="section level3">
<h3><strong>4.3.2 Data Cleaning</strong></h3>
<p>There are <strong>no missing values</strong> in the dataset, so the
data cleaning process is not included.</p>
</div>
</div>
</div>
<div id="exploratory-data-analysis-eda" class="section level1">
<h1><strong>5. Exploratory Data Analysis (EDA)</strong></h1>
<div id="eda-completion-rate" class="section level2">
<h2><strong>5.1 EDA — Completion Rate</strong></h2>
<div id="overview-and-objectives" class="section level3">
<h3>Overview and Objectives</h3>
<p>This section aims to analyze the distribution characteristics of
completion rates and their relationships with key variables, laying the
groundwork for subsequent predictive modeling.</p>
</div>
<div id="data-preprocessing" class="section level3">
<h3>Data Preprocessing</h3>
<p>During data preprocessing, we: - Selected <strong>18 core
features</strong> from the raw dataset: - Engagement metrics (likes,
comments, shares, saves) - Temporal features (upload hour, day of week)
- Content attributes (duration, category, title characteristics) -
Creator attributes (tier, average views) - Converted categorical
variables to appropriate formats - Handled missing values (none found) -
Produced a cleaned dataset of <strong>approximately 48,000
records</strong> with no missing values</p>
</div>
<div id="descriptive-statistics" class="section level3">
<h3>Descriptive Statistics</h3>
<p>Statistical results showed: - <strong>Average completion
rate</strong>: 0.638 (median: 0.642) - <strong>Average views</strong>:
128,000 - <strong>Average engagement rate</strong>: 0.067</p>
<p>These values indicate <strong>moderate audience retention</strong>
and <strong>low-to-moderate interaction</strong> overall.</p>
</div>
<div id="target-variable-distribution" class="section level3">
<h3>Target Variable Distribution</h3>
<div id="completion-rate-symmetric-and-stable" class="section level4">
<h4>Completion Rate: Symmetric and Stable</h4>
<p>Analysis revealed that completion rates exhibit a <strong>roughly
symmetric distribution</strong>, concentrated between 0.6 and 0.7, with:
- No significant skewness - No heavy tails - A stable target for
modeling</p>
</div>
<div id="engagement-rate-right-skewed-with-outliers"
class="section level4">
<h4>Engagement Rate: Right-Skewed with Outliers</h4>
<p>In contrast, engagement rates show a <strong>severe right-skewed
distribution</strong>, with: - Most values below 0.10 - Only a few
high-engagement outliers - Wide variability visible in boxplot
comparisons</p>
</div>
</div>
<div id="relationship-between-completion-and-engagement"
class="section level3">
<h3>Relationship Between Completion and Engagement</h3>
<p>A scatter plot revealed a <strong>weak positive correlation</strong>
(Pearson’s r = 0.12) between completion rate and engagement rate.</p>
<p><strong>Interpretation:</strong> - High retention does not imply high
interaction - The two metrics reflect different aspects of viewer
behavior: - <strong>Completion rate</strong>: Passive retention and
content watchability - <strong>Engagement rate</strong>: Active
interaction and content shareability - Different factors may drive each
outcome</p>
<p>This provides justification for <strong>treating them as independent
outcome variables</strong> in our analysis.</p>
</div>
<div id="temporal-patterns" class="section level3">
<h3>Temporal Patterns</h3>
<div id="upload-timing-analysis" class="section level4">
<h4>Upload Timing Analysis</h4>
<p><strong>Upload Volume by Hour:</strong> - Peak upload times:
<strong>16:00–22:00</strong> (evening hours) - Aligns with users’ active
periods after work/school</p>
<p><strong>Completion Rate by Hour:</strong> - Average completion rates
remain <strong>stable across all time slots</strong> (0.635–0.645) - No
significant variation by upload hour</p>
<p><strong>Weekday vs. Weekend:</strong> - Weekday uploads: 29,953
videos - Weekend uploads: 18,126 videos - Completion rates show
<strong>almost no difference</strong> (0.638 vs. 0.636)</p>
<p><strong>Key Finding:</strong> This result contradicts the initial
hypothesis that “timing affects retention,” indicating that short-form
video viewers’ watching behavior <strong>is not restricted by upload
timing</strong>.</p>
</div>
</div>
<div id="content-characteristics" class="section level3">
<h3>Content Characteristics</h3>
<div id="video-duration-distribution" class="section level4">
<h4>Video Duration Distribution</h4>
<p>Video duration follows a <strong>right-skewed distribution</strong>:
- <strong>78% of videos</strong> are shorter than 50 seconds -
Consistent with short-form video platform norms</p>
</div>
<div id="duration-and-completion-rate-relationship"
class="section level4">
<h4>Duration and Completion Rate Relationship</h4>
<p>A <strong>non-linear relationship</strong> exists between duration
and completion rate: - Completion rates <strong>peak at approximately 12
seconds</strong> (0.68) - Rates <strong>decline steadily</strong> as
duration increases - Videos longer than 120 seconds drop to <strong>0.52
completion rate</strong></p>
<p><strong>Duration Intervals Created:</strong> - &lt;15s - 15-30s -
30-60s - &gt;60s</p>
<p>These intervals facilitate subsequent group analysis.</p>
</div>
</div>
<div id="title-characteristics" class="section level3">
<h3>Title Characteristics</h3>
<div id="title-length" class="section level4">
<h4>Title Length</h4>
<p>Title lengths are concentrated between <strong>10–40
characters</strong>, with: - No consistent monotonic relationship
between length and completion rate - Suggests length alone is not a
strong predictor</p>
</div>
<div id="emoji-usage-a-significant-factor" class="section level4">
<h4>Emoji Usage: A Significant Factor</h4>
<p><strong>Videos with emojis in titles show:</strong> - <strong>Average
completion rate</strong>: 0.659 - <strong>3.2% higher</strong> than
videos without emojis (0.627) - <strong>Engagement rate 41%
higher</strong> (0.095 vs. 0.067)</p>
<p><strong>Additional observations:</strong> - Higher medians for both
completion and engagement rates - Fewer low-performance outliers</p>
<p><strong>Interpretation:</strong> Emojis act as <strong>visual
cues</strong> that enhance initial audience interest and retention.</p>
</div>
</div>
<div id="category-analysis" class="section level3">
<h3>Category Analysis</h3>
<div id="completion-rate-by-content-category" class="section level4">
<h4>Completion Rate by Content Category</h4>
<p>Completion rates vary significantly by content category:</p>
<p><strong>Highest performers:</strong> - <strong>Music</strong>: ~0.67
median - <strong>Fitness</strong>: ~0.67 median</p>
<p><strong>Lowest performers:</strong> - <strong>Education</strong>:
~0.59 median - <strong>Technology</strong>: ~0.59 median</p>
</div>
<div id="duration-category-interaction" class="section level4">
<h4>Duration-Category Interaction</h4>
<p>When stratified by duration and category: - <strong>Music
videos</strong> maintain relatively high completion rates even in longer
intervals (30–60s: 0.64) - <strong>Education videos</strong> see a sharp
drop to 0.51 in the same interval</p>
<p><strong>Key Insight:</strong> Category-specific content quality
moderates the impact of duration on retention: - <strong>Music</strong>:
High appeal maintains engagement - <strong>Education</strong>:
Information density may create fatigue</p>
</div>
</div>
</div>
<div id="eda-trend-label" class="section level2">
<h2><strong>5.2 EDA — Trend Label</strong></h2>
<div id="motivation-for-trend-labels" class="section level3">
<h3>Motivation for Trend Labels</h3>
<p>To go beyond single-metric limitations and comprehensively capture
content popularity, we constructed an <strong>“engagement
score”</strong> by integrating multiple engagement-related features,
then generated trend labels.</p>
</div>
<div id="engagement-score-construction" class="section level3">
<h3>Engagement Score Construction</h3>
<p>The engagement score formula:</p>
<pre><code>Engagement Score = 
  Comment Rate (20% weight) +
  Share Rate (30% weight) +
  Views (20% weight) +
  Text Richness (10% weight) +
  Weekend Effects (10% weight) +
  Creator Tier Bonuses (0–0.5)</code></pre>
</div>
<div id="trend-label-categories" class="section level3">
<h3>Trend Label Categories</h3>
<p>Based on engagement scores, videos were categorized into three trend
labels:</p>
<table>
<thead>
<tr class="header">
<th>Trend Label</th>
<th>Engagement Score</th>
<th>Distribution</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Low Trend</strong></td>
<td>≤ 0.8</td>
<td>42%</td>
</tr>
<tr class="even">
<td><strong>Medium Trend</strong></td>
<td>0.8 &lt; score ≤ 1.5</td>
<td>47%</td>
</tr>
<tr class="odd">
<td><strong>High Trend</strong></td>
<td>&gt; 1.5</td>
<td>11%</td>
</tr>
</tbody>
</table>
<p>The distribution shows <strong>mild imbalance</strong> with more Low
Trend content.</p>
</div>
<div id="engagement-score-distribution-by-trend-label"
class="section level3">
<h3>Engagement Score Distribution by Trend Label</h3>
<p>The distribution shows <strong>clear differentiation</strong>: -
<strong>Low Trend</strong>: 0.6–0.8 - <strong>Medium Trend</strong>:
1.0–1.5 - <strong>High Trend</strong>: 1.8–3.0</p>
<p><strong>Low overlap</strong> between categories validates the
effectiveness of trend labels in stratifying content popularity.</p>
</div>
<div id="platform-comparison" class="section level3">
<h3>Platform Comparison</h3>
<div id="tiktok-vs.-youtube-shorts" class="section level4">
<h4>TikTok vs. YouTube Shorts</h4>
<p>TikTok videos have <strong>higher median engagement scores</strong>
than YouTube Shorts across all trend labels:</p>
<p><strong>Example (High Trend):</strong> - TikTok: 2.3 - YouTube:
1.9</p>
<p><strong>Interpretation:</strong> TikTok’s algorithm or user base is
<strong>more likely to drive high-interaction content</strong>.</p>
</div>
<div id="device-type-no-significant-impact" class="section level4">
<h4>Device Type: No Significant Impact</h4>
<p>Mobile and desktop users show <strong>nearly identical median
scores</strong> for each trend label.</p>
<p><strong>Key Finding:</strong> Content popularity—rather than viewing
device—determines interaction levels.</p>
</div>
</div>
<div id="core-metrics-by-trend-label" class="section level3">
<h3>Core Metrics by Trend Label</h3>
<p>Boxplots reveal a <strong>strong monotonic relationship</strong>:
views, likes, comments, shares, and saves all increase significantly
with trend label level.</p>
<div id="high-trend-vs.-low-trend-comparison" class="section level4">
<h4>High Trend vs. Low Trend Comparison</h4>
<table>
<thead>
<tr class="header">
<th>Metric</th>
<th>High Trend</th>
<th>Low Trend</th>
<th>Ratio</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Median Views</strong></td>
<td>380,000</td>
<td>45,000</td>
<td>8.4×</td>
</tr>
<tr class="even">
<td><strong>Median Likes</strong></td>
<td>18,000</td>
<td>1,200</td>
<td>15×</td>
</tr>
<tr class="odd">
<td><strong>Engagement Rate</strong></td>
<td>0.145</td>
<td>0.032</td>
<td>4.5×</td>
</tr>
</tbody>
</table>
<p><strong>Confirmation:</strong> Trend labels effectively aggregate
multi-dimensional popularity metrics.</p>
</div>
</div>
<div id="creator-analysis" class="section level3">
<h3>Creator Analysis</h3>
<div id="creator-average-views-vs.-individual-video-performance"
class="section level4">
<h4>Creator Average Views vs. Individual Video Performance</h4>
<p>There is a <strong>positive correlation</strong> (r = 0.48) between a
creator’s average views and individual video views, but with
<strong>high dispersion</strong>.</p>
</div>
<div id="creator-tier-impact" class="section level4">
<h4>Creator Tier Impact</h4>
<p>Star creators have a <strong>median engagement score 3.2× that of
Micro creators</strong>, reflecting the <strong>“influence
effect”</strong>: - Larger audience base provides initial exposure -
Creator credibility enhances audience trust</p>
</div>
<div id="important-caveat" class="section level4">
<h4>Important Caveat</h4>
<p><strong>High dispersion</strong> indicates: - Micro creators can
still produce viral videos - Star creators may have underperforming
content</p>
<p><strong>Conclusion:</strong> Creator tier is an important predictive
factor, but <strong>content-specific features remain
critical</strong>.</p>
</div>
</div>
<div id="hashtag-analysis" class="section level3">
<h3>Hashtag Analysis</h3>
<div id="popular-hashtags-drive-massive-views" class="section level4">
<h4>Popular Hashtags Drive Massive Views</h4>
<p>Popular hashtags like: - <strong>#FYP</strong> (For You Page) -
<strong>#GRWM</strong> (Get Ready With Me)</p>
<p>These drive <strong>billions of views</strong> and serve as key
channels for content discovery.</p>
</div>
<div id="niche-hashtags-precision-targeting" class="section level4">
<h4>Niche Hashtags: Precision Targeting</h4>
<p>Niche hashtags like: - <strong>#BookTok</strong> (book-related) -
<strong>#StudyWithMe</strong> (study-along)</p>
<p>These have: - Lower view counts - Precise, engaged audiences</p>
<p><strong>Strategic Insight:</strong> Creators should <strong>combine
popular and niche hashtags</strong> to balance exposure and audience
relevance.</p>
</div>
</div>
<div id="platform-differences-in-trend-distribution"
class="section level3">
<h3>Platform Differences in Trend Distribution</h3>
<div id="tiktok-vs.-youtube-shorts-1" class="section level4">
<h4>TikTok vs. YouTube Shorts</h4>
<p>Significant differences exist in trend label distribution:</p>
<table>
<thead>
<tr class="header">
<th>Platform</th>
<th>High Trend</th>
<th>Low Trend</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>TikTok</strong></td>
<td>13%</td>
<td>38%</td>
</tr>
<tr class="even">
<td><strong>YouTube Shorts</strong></td>
<td>8%</td>
<td>47%</td>
</tr>
</tbody>
</table>
</div>
<div id="engagement-rate-distribution" class="section level4">
<h4>Engagement Rate Distribution</h4>
<ul>
<li><strong>TikTok</strong>: More right-skewed with more high-engagement
outliers</li>
<li><strong>YouTube Shorts</strong>: More clustered at low levels</li>
</ul>
</div>
<div id="algorithmic-interpretation" class="section level4">
<h4>Algorithmic Interpretation</h4>
<p>This reflects that: - <strong>TikTok’s algorithm</strong> (e.g., For
You Page focus on novelty and popularity) is more likely to drive
content virality - <strong>YouTube Shorts</strong> may prioritize
established creators or longer content</p>
</div>
</div>
</div>
</div>
<div id="detailed-regression-ml-analysis" class="section level1">
<h1><strong>6 Detailed Regression &amp; ML Analysis</strong></h1>
<div id="topic-1-completion-rate-analysis" class="section level2">
<h2><strong>6.1 Topic 1: Completion Rate Analysis</strong></h2>
<div id="purpose-of-the-regression-analysis" class="section level3">
<h3><strong>6.1.1 Purpose of the Regression Analysis</strong></h3>
<p>Completion rate serves as a key performance metric for short-form
videos, reflecting how fully viewers watch a given video. Although
creators often attribute retention to content quality, narrative
structure, or emotional engagement, these elements are unobserved in
platform metadata. Our modeling objective is therefore not prediction,
but descriptive quantification of associations between completion_rate
and observable characteristics such as duration, engagement metrics,
posting timing, and creator attributes.</p>
<p>Given the inherent limitations of metadata and the complexity of
viewer behavior — shaped by recommendation algorithms, scrolling
patterns, and individual preferences — we expect the explanatory power
of the regression models to be modest. Nonetheless, regression analysis
still offers a clear way to assess which metadata features are
associated with completion rate and to identify where nonlinear or
structural patterns may warrant more flexible models.</p>
</div>
<div id="linear-regression-models" class="section level3">
<h3><strong>6.1.2 Linear Regression Models</strong></h3>
<p>We first developed three linear models to examine these associations:
(1) a baseline regression including only timing-related features; (2) an
engagement-augmented model that incorporates log-transformed interaction
metrics; and (3) a full specification that adds creator-level attributes
and applies backward stepwise selection to identify a more parsimonious
set of predictors. This progression allowed us to evaluate how the
explanatory contribution of different variable groups changes as the
model becomes more comprehensive. We then extended the analysis to
nonlinear GAM models to assess whether more flexible functional forms
capture additional structure or improve explanatory performance beyond
what linear models can provide.</p>
<div id="baseline-linear-regression" class="section level4">
<h4><strong>6.1.2.1 Baseline Linear Regression</strong></h4>
<p>The baseline regression evaluates how timing-related features and
basic video attributes relate to completion_rate. The estimated model
is:</p>
<p><span class="math display">\[
\begin{aligned}
\text{completion_rate}_i
&amp;= \beta_0
+ \beta_1 \,\text{event_season}_i
+ \beta_2 \,\text{is_weekend}_i \\
&amp;\quad + \beta_3 \,\text{duration_sec}_i
+ \beta_4 \,\text{upload_hour}_i
+ \varepsilon_i .
\end{aligned}
\]</span></p>
<div style="text-align: center;">
<img src="regression_images/model1.png" width="100%">
<p>
Table 6.1    Summary of baseline linear regression
</p>
</div>
<p>Table 6.1 reports the estimated coefficients and summarizes how basic
timing and structural attributes relate to completion rate. The
intercept reflects the expected completion rate for the reference
category, and while not substantively meaningful on its own, it serves
as the baseline against which other coefficients are interpreted.
Consistent with expectations, video duration emerges as the strongest
predictor: the coefficient for <code>duration_sec</code> is negative
(<span class="math inline">\(\beta_3\)</span> = -0.0009) and highly
significant (p-value &lt; 0.05), indicating that longer videos tend to
yield lower completion rates, even within the short-form format. Among
the seasonal indicators, only the Regular season shows a small positive
association (p-value = 0.041 &lt; 0.05). The remaining
<code>event_season</code> categories, as well as <code>is_weekend</code>
and <code>upload_hour</code>, do not exhibit statistically significant
effects, suggesting that broad posting time patterns have limited
influence on completion rate in this dataset.</p>
<p>Overall, the baseline model highlights duration as the primary
structural correlate of viewer retention, while other timing-related
features contribute little explanatory power. This motivates the
incorporation of engagement and creator-level variables in subsequent
models.</p>
</div>
<div id="engagement-augmented-linear-regression" class="section level4">
<h4><strong>6.1.2.2 Engagement-Augmented Linear Regression</strong></h4>
<p>To explore whether audience interaction patterns co-vary with viewer
retention, the second model adds log-transformed engagement metrics —
likes, comments, shares, and saves — to the baseline specification.
These variables allow us to examine the relationship between video
engagement signals and completion rates. The augmented model is
presented as follows:</p>
<p><span style="font-size: 95%;"> <span class="math display">\[
\begin{aligned}
\text{completion_rate}_i
&amp;= \beta_0
+ \beta_1 \,*\text{event_season}_i
+ \beta_2 \,*\text{is_weekend}_i
+ \beta_3 \,*\text{duration_sec}_i \\
&amp;\quad + \beta_4 \,*\text{upload_hour}_i + \beta_5
*\log(\text{likes}_i + 1)
+ \beta_6 *\log(\text{comments}_i + 1) \\
&amp;\quad + \beta_7 *\log(\text{shares}_i + 1)
+ \beta_8 *\log(\text{saves}_i + 1)
+ \varepsilon_i .
\end{aligned}
\]</span> </span></p>
<div style="text-align: center;">
<img src="regression_images/model2.png" width="100%">
<p>
Table 6.2    Summary of engagement-augmented linear regression
</p>
</div>
<p>Table 6.2 presents the augmented model. Duration remains the
strongest negative predictor, consistent the baseline finding. Among
engagement metrics, <code>log_likes</code> and <code>log_saves</code>
show statistically significant positive associations with
<code>completion_rate</code> (p &lt; 0.05). This pattern indicates that
videos with stronger engagement signals also tend to have higher
completion rates, although the association is correlational rather than
causal. In contrast, <code>log_comments</code> and
<code>log_shares</code> are not significant, indicating that not all
engagement forms are linked to retention. The timing-related predictors
(<code>event_season</code>, <code>is_weekend</code>, and
<code>upload_hour</code>) continue to show limited explanatory value,
reinforcing that temporal posting patterns do not strongly shape viewer
retention.</p>
<p>Overall, expanding the model to incorporate interaction measures
offers a modest improvement but does not fundamentally change the
structure of associations identified earlier.</p>
</div>
<div id="full-linear-model-and-stepwise-selection"
class="section level4">
<h4><strong>6.1.2.3 Full Linear Model and Stepwise
Selection</strong></h4>
<p>To examine whether creator attributes or stylistic choices add
explanatory value beyond engagement patterns, the third model introduces
creator-level variables such as log_creator_avg, creator_tier, and
has_emoji. We define the full model as follows:</p>
<p><span style="font-size: 95%;"> <span class="math display">\[
\begin{aligned}
\text{completion_rate}_i
&amp;= \beta_0
+ \beta_1 \,*\text{event_season}_i
+ \beta_2 \,*\text{is_weekend}_i
+ \beta_3 \,*\text{duration_sec}_i
+ \beta_4 \,*\text{upload_hour}_i \\
&amp;\quad + \beta_5 *\log(\text{likes}_i + 1)
+ \beta_6 *\log(\text{comments}_i + 1)
+ \beta_7 *\log(\text{shares}_i + 1)
+ \beta_8 *\log(\text{saves}_i + 1) \\
&amp;\quad + \beta_9 *\log(\text{creator_avg_views}_i + 1)
+ \beta_{10} *\text{creator_tier}_i
+ \beta_{11} *\text{has_emoji}_i
+ \varepsilon_i .
\end{aligned}
\]</span> </span></p>
<p>Because the full specification contains numerous correlated
predictors, a backward stepwise procedure is applied to identify a more
concise subset of variables. The results of final model are presented in
Table 6.3.</p>
<div style="text-align: center;">
<img src="regression_images/model3.png" width="100%">
<p>
Table 6.3    Summary of stepwise (backward) regression
</p>
</div>
<p><span style="font-size: 95%;"> <span class="math display">\[
\begin{aligned}
\widehat{\text{completion_rate}}_i
&amp;= \ 0.6638
- 0.0007932 \,*\text{duration_sec}_i
+ 0.008618 *\log(\text{likes}_i + 1) \\
&amp;\quad + 0.002520 *\log(\text{saves}_i + 1)
- 0.008323 *\log(\text{creator_avg_views}_i + 1) \\
&amp;\quad + 0.02303\, *\text{has_emoji}_i .
\end{aligned}
\]</span> </span></p>
<p>The backward stepwise model finally retains only five predictors —
<code>duration_sec</code>, <code>log_likes</code>,
<code>log_saves</code>, <code>log_creator_avg</code>, and
<code>has_emoji</code> — indicating that these features are the ones
most strongly associated with variation in completion rate. The negative
coefficient for <code>log_creator_avg</code> is particularly notable.
Holding other factors constant, videos from creators with larger average
viewership tend to show slightly lower completion rates. This may
reflect heterogeneous audience behavior or differences in content style
across creator tiers. Meanwhile, <code>has_emoji</code> shows a small
but statistically significant positive effect, suggesting that visual
cues in titles may enhance viewer engagement. Variables removed during
stepwise selection, such as the seasonal and posting-time indicators,
contributed little once the more informative predictors were
included.</p>
<p>Overall, the stepwise model produces a concise set of variables
strongly linked to completion rate. This provides a clear summary of the
linear relationships, establishing a useful baseline for further
exploration.</p>
</div>
<div id="comparison-of-linear-models" class="section level4">
<h4><strong>6.1.2.4 Comparison of Linear Models</strong></h4>
<p>The three linear models show small but incremental improvements in
fit as additional predictors are added. As shown in Table 6.4, the
baseline model explains only a small share of variation in
<code>completion_rate</code> (r-squared = 0.0183). Adding engagement
variables increases the r-squared to 0.0308, and the stepwise model
achieves the highest value at 0.0411.</p>
<div style="text-align: center;">
<img src="regression_images/linear_regression_comparison.png" width="60%">
<p>
Table 6.4    Comparison of linear regression models
</p>
</div>
<p>Despite these incremental differences, all three models ultimately
exhibit low r-squared. This is unsurprising in the context of short-form
video performance, where much of viewer retention is shaped by factors
not captured in metadata - such as creative quality, editing style,
narrative pacing, emotional tone, and topic relevance. Completion
outcomes are also influenced by platform recommendation systems, which
shape exposure patterns in ways not observable in the dataset. Moreover,
linear models impose additive and monotonic relationships that may be
too restrictive for inherently nonlinear viewing behaviors. Together,
these unobserved elements limit the explanatory power of linear models
and help clarify why metadata-based regressions account for only a small
fraction of the variation in completion rate.</p>
</div>
<div id="regression-diagnostics" class="section level4">
<h4><strong>6.1.2.5 Regression Diagnostics</strong></h4>
<p>To assess whether the stepwise model satisfies key regression
assumptions, we examine the standard set of diagnostic plots. These
plots provide insight into linearity, homoscedasticity, normality of
residuals, and the influence of individual observations.</p>
<div style="text-align: center;">
<p>
Figure 6.1    Diagnostic plots for the stepwise linear model
</p>
<p><img src="regression_images/diagnostic_checks.png" width="100%"></p>
</div>
<p>The Residuals vs Fitted and Scale–Location plots show slight changes
in residual spread across fitted values, indicating mild
heteroscedasticity and some non-linearity. The Q–Q plot reveals
noticeable deviations in the tails from a normal distribution; however,
this is also expected because Q–Q plots become highly sensitive with
large sample sizes and can highlight even very small departures from
normality. The Residuals vs Leverage plot shows a few moderately
high-leverage points, but none appear strongly influential.</p>
<p>Overall, the linear model remains adequate for exploratory purposes,
but the diagnostics indicate that its assumptions are not fully
satisfied and the linear specification may not fully capture the
underlying patterns in the data. These limitations motivate the use of
nonlinear approaches, such as smooth and wiggly GAM, to capture
potential nonlinear patterns that the linear specification may not fully
capture.</p>
</div>
</div>
<div id="nonlinear-modeling-and-model-comparison"
class="section level3">
<h3><strong>6.1.3 Nonlinear Modeling and Model Comparison</strong></h3>
<p>Building on the predictors retained from the stepwise linear model,
we extend the analysis to nonlinear specifications to assess whether
more flexible functional forms can better capture patterns in
completion_rate. In particular, we compare a standard linear model with
two generalized additive models (GAMs) that allow nonlinear effects of
the predictors.</p>
<div id="traintest-split-for-nonlinear-models" class="section level4">
<h4><strong>6.1.3.1 Train–Test Split for Nonlinear Models</strong></h4>
<p>To evaluate predictive performance while avoiding overfitting, we
randomly sampled 5,000 observations from the full dataset and applied
the same preprocessing steps used in earlier models. The resulting
dataset was then partitioned into an 80% training set and a 20% test
set. All nonlinear models were fit on the training data and evaluated on
the held-out test data.</p>
</div>
<div id="model-specifications-linear-vs-smooth-vs-wiggly-gam"
class="section level4">
<h4><strong>6.1.3.2 Model Specifications: Linear vs Smooth vs Wiggly
GAM</strong></h4>
<p>We estimate three models using the same predictor set identified
through stepwise selection:</p>
<ol style="list-style-type: decimal">
<li><p>Linear Model — assumes additive, linear effects for all
predictors.</p></li>
<li><p>Smooth GAM — allows predictors such as duration_sec to vary
smoothly, capturing gentle nonlinear trends.</p></li>
<li><p>Wiggly GAM — uses a higher degree of smoothness flexibility,
allowing complex and rapidly changing nonlinear shapes.</p></li>
</ol>
<p>These models represent a progression from simple to increasingly
flexible structures, enabling assessment of whether added nonlinearity
improves fit or merely introduces noise.</p>
</div>
<div id="visual-comparison-of-three-models" class="section level4">
<h4><strong>6.1.3.3 Visual Comparison of three models</strong></h4>
<p>To illustrate differences in model behavior, we visualize fitted
values against <code>duration_sec</code>, because it is a continuous
predictor that allows the linear, smooth, and wiggly models to produce
interpretable fitted curves. Variables such as <code>log_likes</code> or
<code>has_emoji</code> are either discrete or less suitable for
illustrating non-linear patterns.</p>
<div style="text-align: center;">
<p>
Figure 6.2    Visual comparison of linear, smooth GAM, and wiggly GAM
fits
</p>
<img src="regression_images/nonlinear_comparison.png" width="100%">
</div>
<p>Across all three models, the downward association between video
duration and completion_rate is clearly visible. The Linear Model
produces a simple declining line, while the Smooth GAM allows gradual
curvature but remains stable and consistent with overall trends. In
contrast, the Wiggly GAM shows highly fluctuating and unstable fits,
suggesting overfitting to noise rather than capturing meaningful
structure.</p>
</div>
<div id="cross-validation-performance-and-visualization"
class="section level4">
<h4><strong>6.1.3.4 Cross-Validation Performance and
Visualization</strong></h4>
<p>Although prediction is not the primary goal of our analysis,
cross-validated RMSE provides a useful way to compare how differently
structured models behave out of sample and whether added flexibility
leads to more stable estimates. Rather than interpreting RMSE as a
measure of forecasting accuracy, we use it here to assess the extent to
which each model captures consistent patterns versus overfitting
noise.</p>
<div style="text-align: center;">
<p>
Figure 6.3    RMSE distributions for the linear and GAM models
</p>
<p><img src="regression_images/RMSE_distribution.png" width="100%"></p>
</div>
<p>The RMSE distributions show that the Linear Model and Smooth GAM
produce similarly low and stable error levels across folds, indicating
that their fitted relationships generalize reasonably well to held-out
data. In contrast, the Wiggly GAM exhibits both higher RMSE values and
substantially greater variability, showing the instability observed in
its fitted curve. This pattern reinforces the conclusion that excessive
model flexibility primarily captures sampling noise rather than
meaningful structure in the relationship between duration and completion
rate.</p>
<p>Overall, these results suggest that modest nonlinear flexibility can
be informative, but highly wiggly specifications offer little additional
insight and reduce model stability. This indicates that simpler models
are better suited for summarizing the underlying relationships in the
data and align well with the exploratory goals of Topic 1.</p>
</div>
</div>
<div id="conclusion-of-regression-findings" class="section level3">
<h3><strong>6.1.4 Conclusion of Regression Findings</strong></h3>
<p>The regression analyses collectively provide a structured overview of
how metadata features relate to short-form video completion rates.
Across all model specifications, video duration consistently emerges as
the strongest and most stable correlate of completion rate, exhibiting a
negative association in all models. Engagement-related variables such as
<code>log_likes</code> and <code>log_saves</code> also contribute
meaningfully once introduced, suggesting that videos that prompt
stronger viewer interaction tend to retain audiences slightly better.
Creator-level factors, particularly <code>log_creator_avg</code>, show
weaker and inverse relationships, indicating that larger creators do not
necessarily achieve higher completion rates.</p>
<p>Although adding predictors improves model fit incrementally, the
overall explanatory power remains low, with the best linear model
achieving an r-squared of approximately 0.041. This reflects the
inherent limitation of metadata, as viewer retention is a complex
outcome shaped by uncaptured features such as creative quality,
narrative structure, editing choices, emotional resonance, and platform
dynamics.</p>
<p>Nonlinear modeling further highlights these constraints. The Smooth
GAM captures mild curvature but offers only marginal improvements over
the linear specification, while the Wiggly GAM overfits and performs
poorly out of sample. Therefore, these results show that more flexible
functional forms do not substantially enhance predictive accuracy,
reinforcing the conclusion that metadata explains only a small portion
of completion behavior.</p>
<p>Overall, the regression analysis provides useful descriptive insight
into how structural and engagement-related attributes relate to
completion rate, but it also underscores the central role of unobserved
creative and algorithmic factors. These findings motivate the
exploration of richer feature sets or alternative modeling approaches in
future work, while also providing a clear baseline for interpreting
patterns in video performance.</p>
</div>
</div>
<div id="topic-2-trend-prediction" class="section level2">
<h2><strong>6.2 Topic 2: Trend Prediction</strong></h2>
<div id="purpose-of-the-ml-analysis" class="section level3">
<h3><strong>6.2.1 Purpose of the ML Analysis</strong></h3>
<p>We applyed several algorthms designed to predict popularity trends
for short-form videos. By analyzing extensive video data, we identify
patterns in viral content and assess the breakout potential of new
videos. By testing multiple algorithms, we identify the most accurate
predictive model, providing data-driven support for content platforms,
creators, and advertisers.</p>
</div>
<div id="data-preparation-and-exploration" class="section level3">
<h3><strong>6.2.2 Data Preparation and Exploration</strong></h3>
<div id="dataset-characteristics" class="section level4">
<h4><strong>6.2.2.1 Dataset Characteristics</strong></h4>
<p>We created a simulated dataset of 50,000 samples with the following
characteristics:</p>
<ul>
<li><p><strong>Platform Distribution</strong>: 60% TikTok, 40%
YouTube</p></li>
<li><p><strong>Content Categories</strong>: Entertainment, Music,
Sports, Education, Gaming</p></li>
<li><p><strong>Creator Tiers</strong>: Micro (50%), Mid (30%), Macro
(15%), Star (5%)</p></li>
<li><p><strong>Key Metrics</strong>: Title length, text richness,
comment rate, share rate, daily views</p></li>
</ul>
</div>
</div>
<div id="target-variable-construction" class="section level3">
<h3><strong>6.2.2.2 Target Variable Construction</strong></h3>
<p>We constructed an <strong>Engagement Score</strong> using the
following weighted formula:</p>
<p><span class="math display">\[
\begin{aligned}
\text{Engagement Score} = &amp;
\left(\frac{\text{comment_rate}}{0.02}\right) \times 0.2 \\
                         &amp; +
\left(\frac{\text{share_rate}}{0.005}\right) \times 0.3 \\
                         &amp; +
\left(\frac{\text{views_per_day}}{50000}\right) \times 0.2 \\
                         &amp; + \text{text_richness} \times 0.1 \\
                         &amp; + \text{weekend_hashtag_boost} \times 0.1
\\
                         &amp; + \text{creator_tier_bonus} \\
                         &amp; + N(0, 0.2)
\end{aligned}
\]</span></p>
<p>Where the creator tier bonus is defined as:</p>
<p><span class="math display">\[
\text{creator_tier_bonus} =
\begin{cases}
0.5 &amp; \text{if Star} \\
0.3 &amp; \text{if Macro} \\
0.1 &amp; \text{if Mid} \\
0 &amp; \text{if Micro}
\end{cases}
\]</span></p>
<p>Based on the Engagement Score, videos are classified into three trend
categories:</p>
<ul>
<li><p><strong>Low Trend (0)</strong>: Engagement Score ≤ 0.8</p></li>
<li><p><strong>Medium Trend (1)</strong>: 0.8 &lt; Engagement Score ≤
1.5</p></li>
<li><p><strong>High Trend (2)</strong>: Engagement Score &gt;
1.5</p></li>
</ul>
</div>
<div id="feature-engineering" class="section level3">
<h3><strong>6.2.3 Feature Engineering</strong></h3>
<p>We created three interaction features to capture complex
relationships:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Platform-Tier Interaction</strong>: Combines platform
type with creator tier</p>
<p><span class="math display">\[
\text{platform_tier} = \text{platform} \oplus \text{creator_tier}
\]</span></p></li>
<li><p><strong>Region-Category Interaction</strong>: Combines geographic
region with content category</p>
<p><span class="math display">\[
\text{region_category} = \text{region} \oplus \text{category}
\]</span></p></li>
<li><p><strong>Engagement Velocity</strong>: Composite metric measuring
virality speed</p>
<p><span class="math display">\[
\text{engagement_velocity} = \text{views_per_day} \times
(\text{comment_rate} + \text{share_rate})
\]</span></p></li>
</ol>
<p>Where <span class="math inline">\(\oplus\)</span> denotes feature
concatenation.</p>
<p>The final model utilizes 15 features including:</p>
<ul>
<li><p>12 original features (platform, region, category, traffic_source,
device_brand, creator_tier, title_len, text_richness, comment_rate,
share_rate, views_per_day, weekend_hashtag_boost)</p></li>
<li><p>3 interaction features (platform_tier, region_category,
engagement_velocity)</p></li>
</ul>
</div>
<div id="data-preprocessing-1" class="section level3">
<h3><strong>6.2.4 Data Preprocessing</strong></h3>
<div id="data-splitting" class="section level4">
<h4><strong>6.2.4.1 Data Splitting</strong></h4>
<p>The dataset was randomly split into training (80%) and testing (20%)
sets while maintaining proportional representation of each trend class
in both subsets.</p>
</div>
<div id="feature-transformation" class="section level4">
<h4><strong>6.2.4.1 Feature Transformation</strong></h4>
<ul>
<li><p><strong>Numerical Features</strong>: Standardized to zero mean
and unit variance</p></li>
<li><p><strong>Categorical Features</strong>: Transformed using one-hot
encoding</p></li>
</ul>
</div>
</div>
<div id="model-definition" class="section level3">
<h3><strong>6.2.5 Model Definition</strong></h3>
<p>We tested six machine learning models:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Random Forest</strong>: Ensemble of 200 decision trees
with maximum depth 15</p></li>
<li><p><strong>Gradient Boosting</strong>: 200 sequential trees with
learning rate <span class="math inline">\(\eta = 0.1\)</span></p></li>
<li><p><strong>Extra Trees</strong>: Extremely randomized trees variant
with 200 estimators</p></li>
<li><p><strong>Neural Network</strong>: Multi-layer perceptron with
architecture <span class="math inline">\([100, 50]\)</span>
neurons</p></li>
<li><p><strong>Support Vector Machine</strong>: RBF kernel with
regularization <span class="math inline">\(C = 1.0\)</span></p></li>
<li><p><strong>Logistic Regression</strong>: Linear classifier with
one-vs-rest strategy</p></li>
</ol>
</div>
<div id="model-training-and-evaluation" class="section level3">
<h3><strong>6.2.6 Model Training and Evaluation</strong></h3>
<div id="evaluation-metrics" class="section level4">
<h4><strong>6.2.6.1 Evaluation Metrics</strong></h4>
<p>Models were evaluated using multiple metrics:</p>
<ul>
<li><p><strong>Accuracy</strong></p></li>
<li><p><strong>Macro-average F1 Score</strong></p></li>
<li><p><strong>Weighted-average F1 Score</strong></p></li>
<li><p><strong>AUC-OVR</strong></p></li>
<li><p><strong>5-Fold Cross-Validation Accuracy</strong></p></li>
</ul>
</div>
<div id="training-process" class="section level4">
<h4><strong>6.2.6.2 Training Process</strong></h4>
<p>All models were trained using identical preprocessing pipelines to
ensure fair comparison, with performance evaluated on the held-out test
set.</p>
</div>
</div>
<div id="results-comparison" class="section level3">
<h3><strong>6.2.7 Results Comparison</strong></h3>
<div id="performance-ranking" class="section level4">
<h4><strong>6.2.7.1 Performance Ranking</strong></h4>
<p>Gradient Boosting demonstrated superior performance across all
metrics:</p>
<p><img src="classification_model_comparison.png" /></p>
</div>
</div>
<div id="best-model-analysis" class="section level3">
<h3><strong>6.2.8 Best Model Analysis</strong></h3>
<p>The Gradient Boosting model achieved the following confusion
matrix:</p>
<p><img src="classification_confusion_matrix.png" /></p>
<p>The model demonstrates strong performance distinguishing Low from
High trends but shows some confusion at the Medium-High boundary, with
206 High-trend videos misclassified as Medium.</p>
</div>
<div id="feature-importance-analysis" class="section level3">
<h3><strong>6.2.9 Feature Importance Analysis</strong></h3>
<p>The Gradient Boosting model revealed the following feature importance
ranking:</p>
<p><img src="classification_feature_importance.png" /></p>
<p>Analysis confirms user interaction metrics (particularly sharing and
commenting) are the primary predictors of video trends, accounting for
65% of the model’s decision-making.</p>
</div>
</div>
</div>
<div id="discussion" class="section level1">
<h1><strong>7. Discussion</strong></h1>
<div id="discussion-of-completion-rate" class="section level2">
<h2><strong>7.1 Discussion of Completion Rate</strong></h2>
<div id="clear-patterns-identified" class="section level3">
<h3>Clear Patterns Identified</h3>
<p>The regression results reveal several clear patterns in the
relationship between video features and view completion rates.</p>
<div id="video-duration-the-dominant-factor" class="section level4">
<h4>Video Duration: The Dominant Factor</h4>
<p>Among all models, <strong>video length consistently has the strongest
influence</strong>: - Longer videos tend to have <strong>lower view
completion rates</strong> - Aligns with expectations for short-video
platforms - Viewers prefer quick and easy-to-understand content</p>
</div>
<div id="interaction-metrics-positive-correlates"
class="section level4">
<h4>Interaction Metrics: Positive Correlates</h4>
<p>Interaction metrics such as <strong>likes and saves</strong> are
positively correlated with view completion rates: - Videos that retain
viewers tend to generate more interaction - Suggests a bidirectional
relationship between retention and engagement</p>
<hr />
</div>
</div>
<div id="surprising-findings" class="section level3">
<h3>Surprising Findings</h3>
<div id="creator-attributes-weak-and-negative-association"
class="section level4">
<h4>Creator Attributes: Weak and Negative Association</h4>
<p>More surprisingly, an unexpected finding is that
<strong>creator-level attributes</strong>, including average historical
views, have a <strong>weak and even negative correlation</strong> with
view completion rates.</p>
<p><strong>Implications:</strong> - Having a large audience does not
guarantee high retention rates - <strong>Content features may be more
important than creator scale</strong> - Challenges assumptions about
influencer effectiveness</p>
<hr />
</div>
</div>
<div id="model-performance-the-low-r-squared-problem"
class="section level3">
<h3>Model Performance: The Low R-Squared Problem</h3>
<p>The <strong>consistently low R-squared value across all
models</strong> indicates that these predictors explain only a
<strong>small portion of the variation</strong> in view completion
rates.</p>
<div id="limited-improvement-from-additional-predictors"
class="section level4">
<h4>Limited Improvement from Additional Predictors</h4>
<p>Adding more predictors provides <strong>limited improvement</strong>,
further suggesting that metadata only captures some of the potential
factors influencing viewer retention.</p>
<p><strong>What’s Missing:</strong> - Creative quality and production
value - Narrative structure and pacing - Emotional resonance - Visual
aesthetics - Algorithmic exposure patterns</p>
<hr />
</div>
</div>
<div id="broader-insights" class="section level3">
<h3>Broader Insights</h3>
<div id="content-quality-over-creator-identity" class="section level4">
<h4>Content Quality Over Creator Identity</h4>
<p>View completion rates appear to depend more on <strong>video-level
quality</strong>, such as: - Content design - Thematic appeal -
Execution quality</p>
<p>Rather than: - Creator’s identity - Posting time - Follower count</p>
</div>
<div id="the-metadata-limitation" class="section level4">
<h4>The Metadata Limitation</h4>
<p>The low R-squared value confirms that <strong>most determinants of
retention</strong>—including creative quality and algorithmic
exposure—are <strong>not reflected in the existing
variables</strong>.</p>
</div>
<div id="non-linear-models-dont-help" class="section level4">
<h4>Non-Linear Models Don’t Help</h4>
<p>The non-linear model shows <strong>little improvement over the linear
model</strong>, suggesting that the primary limitation lies in: -
<strong>The lack of relevant content-level information</strong> - NOT
the functional form of the model</p>
<hr />
</div>
</div>
<div id="conclusion" class="section level3">
<h3>Conclusion</h3>
<p>In conclusion, <strong>metadata can reveal some meaningful
patterns</strong>, but it can only explain a <strong>small fraction of
audience behavior</strong> on short video platforms.</p>
<p><strong>Key Takeaway:</strong> The challenge is not about finding the
right model—it’s about the fundamental limits of what observable
metadata can capture about inherently creative and algorithmic
processes.</p>
<hr />
</div>
</div>
<div id="discussion-of-trend-prediction" class="section level2">
<h2><strong>7.2 Discussion of Trend Prediction</strong></h2>
<div id="expected-vs.-unexpected-findings" class="section level3">
<h3>Expected vs. Unexpected Findings</h3>
<div id="gradient-boosting-performance-as-expected"
class="section level4">
<h4>Gradient Boosting Performance: As Expected</h4>
<p>The superior performance of <strong>Gradient Boosting was
anticipated</strong>, given its proven effectiveness in handling
structured data with complex feature interactions.</p>
</div>
<div id="magnitude-of-difference-beyond-expectations"
class="section level4">
<h4>Magnitude of Difference: Beyond Expectations</h4>
<p>What <strong>exceeded expectations</strong> was the <strong>magnitude
of difference</strong> between models: - Gradient Boosting achieved
<strong>3.2% higher accuracy</strong> than its nearest competitor -
Demonstrates clear superiority for this task</p>
<hr />
</div>
</div>
<div id="system-effectiveness" class="section level3">
<h3>System Effectiveness</h3>
<p>Our research results show that the proposed trend prediction system
<strong>effectively captures meaningful behavioral patterns</strong> in
short video participation.</p>
<div id="clear-category-separation" class="section level4">
<h4>Clear Category Separation</h4>
<p><strong>High, Medium, and Low Trend categories</strong> show clear
and consistent separations in key indicators: - Views - Likes - Comments
- Shares - Saves</p>
</div>
<div id="alignment-with-expectations" class="section level4">
<h4>Alignment with Expectations</h4>
<p>This model is <strong>highly consistent with expectations</strong>: -
The higher the trend of a video, the more user engagement it naturally
accumulates - This accelerates visibility in the platform’s
recommendation ecosystem</p>
<hr />
</div>
</div>
<div id="validation-of-feature-design" class="section level3">
<h3>Validation of Feature Design</h3>
<div id="distribution-of-engagement-scores" class="section level4">
<h4>Distribution of Engagement Scores</h4>
<p>The distribution of engagement scores further validates the
<strong>reliability of the constructed labels</strong>: - Each category
forms a <strong>distinct group</strong> - Indicates that our feature
design has successfully captured the <strong>underlying drivers of viral
spread</strong></p>
</div>
<div id="feature-importance-findings" class="section level4">
<h4>Feature Importance Findings</h4>
<p>Analysis confirms that <strong>user interaction metrics</strong>
(particularly sharing and commenting) are the <strong>primary
predictors</strong> of video trends, accounting for: - <strong>65% of
the model’s decision-making</strong></p>
<p>This validates the theoretical foundation that viral content is
driven by active user participation.</p>
<hr />
</div>
</div>
<div id="practical-implications" class="section level3">
<h3>Practical Implications</h3>
<div id="for-content-creators" class="section level4">
<h4>For Content Creators</h4>
<p>The model provides actionable insights: - Focus on
<strong>share-worthy content</strong> (highest feature importance) -
Optimize for <strong>comment generation</strong> through engaging hooks
- Consider <strong>platform-specific strategies</strong> (TikTok
vs. YouTube Shorts)</p>
</div>
<div id="for-platforms" class="section level4">
<h4>For Platforms</h4>
<p>Understanding trend drivers enables: - Better recommendation
algorithm design - Content moderation prioritization - Creator support
and guidance</p>
</div>
<div id="for-marketers" class="section level4">
<h4>For Marketers</h4>
<p>Trend prediction allows: - Early identification of viral
opportunities - Strategic partnership timing - ROI optimization for
influencer campaigns</p>
</div>
</div>
</div>
</div>
<div id="limitations-and-future-work" class="section level1">
<h1><strong>8. Limitations and Future Work</strong></h1>
<div id="limitations-of-completion-rate-analysis-topic-1"
class="section level2">
<h2><strong>8.1 Limitations of Completion Rate Analysis (Topic
1)</strong></h2>
<div id="heterogeneity-problem-one-model-for-all"
class="section level3">
<h3>Heterogeneity Problem: One Model for All?</h3>
<p>A major limitation of regression analysis is that it <strong>models
all video data as a single merged dataset</strong> without
distinguishing between: - Different platforms (TikTok vs. YouTube
Shorts) - Languages and cultural contexts - Content categories (music,
education, gaming)</p>
<div id="why-this-is-problematic" class="section level4">
<h4>Why This Is Problematic</h4>
<p>Because short videos vary greatly in: - Purpose - Audience
expectations - Cultural context</p>
<p><strong>Merging all observations introduces significant
heterogeneity</strong>, which: 1. <strong>Weakens true
relationships</strong> by averaging across disparate groups 2.
<strong>Makes some predictors insignificant</strong> that might be
strong within specific subgroups 3. <strong>Masks confounding
patterns</strong> that may exist in specific subgroups</p>
</div>
<div id="the-large-sample-exacerbates-the-problem"
class="section level4">
<h4>The Large Sample Exacerbates the Problem</h4>
<p>The large sample size further exacerbates this issue by: - Detecting
statistically significant but practically meaningless effects -
Obscuring meaningful patterns within specific content types</p>
</div>
</div>
<div id="the-low-r-squared-problem" class="section level3">
<h3>The Low R-Squared Problem</h3>
<p>The consistently <strong>low R-squared values</strong> across all
models indicate that the current set of metadata variables captures only
a <strong>small portion of the factors</strong> influencing completion
rate.</p>
<div id="multiple-interpretations" class="section level4">
<h4>Multiple Interpretations</h4>
<p>This weak model fit may reflect: 1. <strong>The limits of
metadata</strong> — creative quality cannot be quantified through
observable features 2. <strong>The absence of important
variables</strong> — content-level or behavior-level variables not
observable in the dataset</p>
</div>
</div>
<div id="recommendations-for-future-research" class="section level3">
<h3>Recommendations for Future Research</h3>
<p>In future research, we should:</p>
<div id="expand-the-breadth-of-observed-variables"
class="section level4">
<h4>1. Expand the Breadth of Observed Variables</h4>
<p>Include: - Content-level features (visual quality, editing pace,
music choice) - Behavior-level features (scroll patterns, replays, pause
behavior) - Algorithmic features (recommendation score, position in
feed)</p>
</div>
<div id="use-stratified-or-subgroup-analysis" class="section level4">
<h4>2. Use Stratified or Subgroup Analysis</h4>
<p>Better control the model by: - <strong>Modeling completion rate
separately</strong> by language or platform - Determining whether
observed correlations are <strong>consistent across different content
types</strong> - Identifying <strong>confounding factors specific to
each category</strong></p>
<p><strong>Example Applications:</strong> - Analyze whether duration
effects differ for education vs. entertainment content - Test whether
creator tier matters more on TikTok than YouTube Shorts - Examine
whether emoji effects vary by audience age group</p>
</div>
<div id="benefits-of-stratification" class="section level4">
<h4>Benefits of Stratification</h4>
<p>This approach can: - <strong>Identify category-specific
patterns</strong> masked in aggregate analysis - <strong>Control for
confounding</strong> by analyzing homogeneous subgroups -
<strong>Provide more actionable insights</strong> for content creators
in specific niches</p>
</div>
</div>
</div>
<div id="limitations-of-trend-prediction-topic-2"
class="section level2">
<h2><strong>8.2 Limitations of Trend Prediction (Topic 2)</strong></h2>
<p>Although the proposed system demonstrates <strong>strong predictive
ability</strong> for short video trends, there are still some
limitations providing opportunities for future enhancement.</p>
<div id="data-quality-and-representativeness" class="section level3">
<h3>Data Quality and Representativeness</h3>
<div id="synthetic-data-limitations" class="section level4">
<h4>Synthetic Data Limitations</h4>
<p>The dataset relies on <strong>synthetic or proxy-generated behavioral
patterns</strong>, which means: - The engagement relationships in model
learning may not fully capture <strong>platform-specific
nuances</strong> - May miss <strong>rapidly evolving user
habits</strong> in real-world environments - Lacks the complexity of
actual algorithmic amplification effects</p>
</div>
</div>
<div id="feature-completeness" class="section level3">
<h3>Feature Completeness</h3>
<div id="missing-multimodal-elements" class="section level4">
<h4>Missing Multimodal Elements</h4>
<p>The current feature design mainly focuses on <strong>structured
metadata and digital interaction metrics</strong>, but does not
incorporate:</p>
<p><strong>Visual Features:</strong> - Video content quality - Visual
aesthetics - Color schemes and composition</p>
<p><strong>Audio Features:</strong> - Music choice and tempo - Audio
quality - Sound effects</p>
<p><strong>Text Semantics:</strong> - Title and description sentiment -
Topic modeling - Semantic similarity to trending content</p>
<p><strong>Known Impact:</strong> These multimodal elements are
<strong>known to have a significant impact on viral spread</strong> but
are not currently captured.</p>
</div>
</div>
<div id="temporal-dynamics" class="section level3">
<h3>Temporal Dynamics</h3>
<div id="static-vs.-dynamic-modeling" class="section level4">
<h4>Static vs. Dynamic Modeling</h4>
<p>The <strong>contemporaneity of social trends has been
simplified</strong>: - These models handle <strong>each sample
independently</strong> - Do not model the <strong>dynamic trend
propagation over time</strong></p>
<p><strong>Missing Elements:</strong> - Early momentum signals -
Cascading sharing patterns - Time-to-viral metrics - Trend decay
patterns</p>
</div>
</div>
<div id="model-architecture-opportunities" class="section level3">
<h3>Model Architecture Opportunities</h3>
<div id="current-limitations" class="section level4">
<h4>Current Limitations</h4>
<p>The current model uses traditional machine learning approaches, which
may miss: - Complex sequential dependencies - Long-range feature
interactions - Hierarchical content structures</p>
</div>
<div id="advanced-technologies-for-enhancement" class="section level4">
<h4>Advanced Technologies for Enhancement</h4>
<p>Model performance can be further enhanced through:</p>
<p><strong>1. Transformer-Based Architectures</strong> - Better capture
of sequential patterns - Attention mechanisms for feature importance -
Pre-trained models for transfer learning</p>
<p><strong>2. Self-Supervised Representation Learning</strong> - Learn
rich representations from unlabeled video data - Capture latent features
not in metadata - Reduce dependence on labeled data</p>
<p><strong>3. Automatic Hyperparameter Optimization</strong> - More
efficient model tuning - Better generalization - Reduced human bias in
model selection</p>
</div>
</div>
</div>
<div id="future-work-directions" class="section level2">
<h2><strong>8.3 Future Work Directions</strong></h2>
<div id="data-integration" class="section level3">
<h3>Data Integration</h3>
<div id="real-platform-data-streams" class="section level4">
<h4>Real Platform Data Streams</h4>
<p>Integrating <strong>real platform data streams</strong> would enable:
- Validation of findings on actual user behavior - Capture of
platform-specific algorithmic effects - Real-time trend tracking</p>
</div>
<div id="expanding-the-feature-space" class="section level4">
<h4>Expanding the Feature Space</h4>
<p>Include: - <strong>Visual and NLP-based content signals</strong>
(scene detection, sentiment analysis) - <strong>User trajectory
data</strong> (viewing history, scroll patterns) - <strong>Network
effects</strong> (follower graphs, sharing cascades)</p>
</div>
</div>
<div id="methodological-enhancements" class="section level3">
<h3>Methodological Enhancements</h3>
<div id="time-series-prediction-methods" class="section level4">
<h4>Time Series Prediction Methods</h4>
<p>Adopting <strong>time series approaches</strong> such as: -
<strong>Sequence models</strong> (LSTM, GRU) for temporal dependencies -
<strong>Graph-based diffusion learning</strong> for viral spread
modeling - <strong>Survival analysis</strong> for trend lifecycle
prediction</p>
</div>
<div id="multi-task-learning" class="section level4">
<h4>Multi-Task Learning</h4>
<p>Simultaneously predict: - Trend label - Completion rate - Engagement
metrics</p>
<p>This could capture shared underlying factors and improve overall
performance.</p>
</div>
</div>
<div id="real-world-deployment" class="section level3">
<h3>Real-World Deployment</h3>
<div id="real-time-feedback-loop" class="section level4">
<h4>Real-Time Feedback Loop</h4>
<p>Deploying the model into a <strong>real-time feedback loop</strong>
would: - Enable continuous learning from new data - Adapt to evolving
platform dynamics - Provide immediate value to stakeholders</p>
</div>
<div id="production-constraints-evaluation" class="section level4">
<h4>Production Constraints Evaluation</h4>
<p>Evaluating the model under <strong>production constraints</strong>: -
Latency requirements - Computational costs - Update frequency - Model
interpretability for non-technical users</p>
</div>
</div>
<div id="stakeholder-applications" class="section level3">
<h3>Stakeholder Applications</h3>
<div id="for-content-creators-1" class="section level4">
<h4>For Content Creators</h4>
<p>Future systems could provide: - Real-time trend prediction before
publishing - Optimization suggestions for title, hashtags, timing -
Competitive benchmarking</p>
</div>
<div id="for-marketers-1" class="section level4">
<h4>For Marketers</h4>
<p>Enhanced capabilities for: - Early identification of emerging trends
- Influencer selection and campaign timing - ROI prediction and
optimization</p>
</div>
<div id="for-recommendation-systems" class="section level4">
<h4>For Recommendation Systems</h4>
<p>Integration with platform algorithms for: - Better content discovery
- Personalized trend surfaces - Diversity in trending content</p>
</div>
</div>
</div>
<div id="concluding-thoughts" class="section level2">
<h2><strong>8.4 Concluding Thoughts</strong></h2>
<p>This project demonstrates both the <strong>possibilities and
limitations</strong> of metadata-based analytics for short-form video
performance.</p>
<div id="what-we-learned" class="section level3">
<h3>What We Learned</h3>
<p><strong>Completion Rate:</strong> - Metadata can identify structural
patterns - But cannot capture creative quality - Descriptive insights
are more valuable than predictive accuracy</p>
<p><strong>Trend Prediction:</strong> - Multi-metric engagement signals
are more predictable - Machine learning can effectively classify
popularity levels - Feature engineering is crucial for performance</p>
</div>
<div id="the-path-forward" class="section level3">
<h3>The Path Forward</h3>
<p>The future of short-form video analytics lies in: 1.
<strong>Integrating multimodal data</strong> (visual, audio, text) 2.
<strong>Modeling temporal dynamics</strong> of trend propagation 3.
<strong>Deploying real-time systems</strong> that learn continuously 4.
<strong>Balancing predictive power with interpretability</strong></p>
<p>By addressing these limitations and pursuing these directions, future
work can <strong>further verify the practical value</strong> of trend
prediction systems for content creators, marketers, and recommendation
platforms.</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
